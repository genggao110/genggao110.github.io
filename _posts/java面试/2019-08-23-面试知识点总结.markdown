---
layout:     post
title:      "面试知识点"
subtitle:   " \"知识点总结\""
date:       2019-08-23 20:29:07
author:     "ming"
catalog: true
header-img: "img/post-bg-girl.jpg"
tags:
    - 面试知识点
---

> "The purpose of human life is to serve, and to show compassion and the will to help others."

### 1.Hadoop知识总结

#### 1.1 MR架构

**JobClient、JobTracker、TaskTracker**

![MR架构](https://upload-images.jianshu.io/upload_images/697231-069e09ede059d164?imageMogr2/auto-orient/strip|imageView2/2/w/810/format/webp)

1. JobClient向JobTracker请求一个新的JobId;
2. 检查作业输出说明；
3. 计算作业输出划分split
4. 将运行作业所需的资源(作业的jar文件、配置文件、计算所得的输入划分)复制到一个以作业ID命名的目录JobTracker的文件系统；
5. 通过调用JobClient的submitJob()方法，告诉JobTracker作业准备运行
6. JobTracker接收到submitJob()方法调用后，把此调用放到一个内部队列中，交由作业调度器进行调度，并对其进行初始化；
7. 创建任务运行列表，作业调度去首先从共享文件系统中获取JobClient已经计算好的输入划分信息（图中step6），然后为每个划分创建一个Map任务（一个split对应一个map，有多少split就有多少map）。
8. TaskTracker执行一个简单的循环，定期发送心跳（heartbeat）调用JobTracker。

JobTracker 负责工作节点的资源管理，监控资源的使用情况，管理作业的生命周期。

TaskTracker 的职责是根据JobTracker 的命令启动/清除任务，并且周期性的向JobTracker 汇报任务的状态信息。

**Yarn运行机制**

YARN 的基本思想就是将JobTracker 的两大主要职能：资源管理、作业的调度监控分为两个独立的进程。一个是全局的ResourceManager,另一个是每一个应用对应的ApplicationMaster。

ResourceManager 是一个纯粹的调度器，它根据应用程序的资源请求严格限制系统的可用资源。在保证容量、公平性及服务器等级的前提下，优化集群资源利用率，即让所有的资源都能被充分利用。

ApplicationMaster 负责与ResourceManager 协商资源，并和NodeManager 进行协同工作来执行容器和监控容器的状态。

NodeManager 是YARN 节点上的工作进程，管理集群中独立的计算节点。其职责包括启动应用程序的容器，监控它们的资源使用情况，并且报告给ResourceManager。

![YARN](https://upload-images.jianshu.io/upload_images/697231-ea265a5516b96af5.png?imageMogr2/auto-orient/strip|imageView2/2/w/657/format/webp)

- ResourceManager 代替集群管理器
- ApplicationMaster 代替一个专用且短暂的 JobTracker
- NodeManager 代替 TaskTracker
- 一个分布式应用程序代替一个 MapReduce 作业

一个全局 ResourceManager 以主要后台进程的形式运行，它通常在专用机器上运行，在各种竞争的应用程序之间仲裁可用的集群资源。
在用户提交一个应用程序时，一个称为 ApplicationMaster 的轻量型进程实例会启动来协调应用程序内的所有任务的执行。这包括监视任务，重新启动失败的任务，推测性地运行缓慢的任务，以及计算应用程序计数器值的总和。有趣的是，ApplicationMaster 可在容器内运行任何类型的任务。
NodeManager 是 TaskTracker 的一种更加普通和高效的版本。没有固定数量的 map 和 reduce slots，NodeManager 拥有许多动态创建的资源容器。

#### 1.2 Spark

1. spark有几种部署模式，每种模式特点？

- 本地模式：Spark不一定非要跑在hadoop集群，可以在本地，起多个线程的方式来指定。方便调试，本地模式分三类。
- standalone模式：分布式部署集群，自带完整的服务，资源管理和任务监控是Spark自己监控，这个模式也是其他模式的基础。
- spark on yarn:分布式部署集群，资源和任务监控交给yarn管理;粗粒度资源分配方式，包含cluster和client运行模式(cluster 适合生产，driver运行在集群子节点，具有容错功能;client 适合调试，dirver运行在客户端)
- spark on mesos

2. spark技术栈有哪些组件，每个组件有什么功能，适用于什么应用场景？

- Spark core:是其它组件的基础，spark的内核,其主要包括有向循环图、RDD、Lingage、Cache、broadcast等。
- Spark Streaming:是一个对实时数据流进行高通量、容错处理的流式处理系统,将流式计算分解成一系列短小的批处理作业.
- Spark SQL：能够统一处理关系表和RDD，使得开发人员可以轻松地使用SQL命令进行外部查询。
- MLBase: 是Spark生态圈的一部分专注于机器学习，让机器学习的门槛更低.
- GraphX: 是Spark中用于图和图并行计算.

3. spark有哪些组件?

- master:管理集群和节点，不参与计算；
- worker: 计算节点，进程本身不参与计算，和master汇报。
- Driver: 运行程序的main方法，创建spark context对象；
- Spark Context:控制整个application的生命周期，包括dagsheduler和task scheduler等组件.
- client: 用户提交程序的入口。

4. spark工作机制

- 用户在client端提交任务后，会由Driver运行main方法并创建spark context上下文
- 执行add算子，形成dag图输入dagscheduler
- 按照add之间的依赖关系划分stage输入task scheduler
- task scheduler会将stage划分为taskset分发到各个节点的executor中执行

5. RDD机制

- 分布式弹性数据集，简单的理解成一种数据结构，是spark框架上的通用货币
- 所有算子都是基于rdd来执行的
- rdd执行过程中会形成dag图，然后形成lineage保证容错性等
- 从物理的角度来看rdd存储的是block和node之间的映射

#### 1.3 TODO


