---
layout:      post
title:       "Java Basic Knowledge 2"
subtitle:    " \"Java core technology\""
date:        2019-03-29 10:45:26
author:      "Ming"
catalog: true
header-img:  "img/post-bg-alitrip.jpg"
tags:
    - JAVA
    - Knowledge
---

> "I love and am used to keeping a distance with those changed things. Only in this way can I know what will not be abandoned by time."

### 2. Java高级特性设计

#### 2.1 Java集合框架

Java集合框架下有很类，给出其集合框架图如下所示。(其中，黄色的代表接口，绿色的是抽象类，蓝色的是具体类)。

![Collection集合](https://ws1.sinaimg.cn/large/005CDUpdly1g1jha52x8hj30ou0f8gm4.jpg)

![Map集合](https://ws1.sinaimg.cn/large/005CDUpdly1g1jhb3ta1aj30n60asq32.jpg)

TreeSet类与散列集(HashSet)十分类似，不过它比散列集有所改进。树集是一个**有序集合**(sorted collection)。可以以任意顺序将元素插入到集合中。在对集合进行遍历时，每个值自动地按照排序后的顺序呈现。排序是用树结构完成的(目前所实现使用的是红黑树)。(**注意**：对于要使用树集，必须能够比较元素。即这些元素必须实现Comparable接口，或者构造集时必须提供一个Comparator。)

Eg: 具体内容参考Java核心技术书籍。

#### 2.2 并发

学习中,后期补充....

#### 2.3 Java SE8的流库

**流和集合之间的区别：**

- 流并不存储其数据。这些元素可能存储在底层的集合中，或者是按需生成的。
- 流的操作不会修改其数据源。例如，filter方法不会从新的流中移除元素，而是会生成一个新的流，其中不包括被过滤掉的元素。
- 流的操作是尽可能惰性执行的。这意味着直至需要其结果时，操作才会执行。





### 1.2 Map接口

![Map集合](https://ws1.sinaimg.cn/large/005CDUpdly1g1jhb3ta1aj30n60asq32.jpg)

Map用于保存具有映射关系的数据，它是由一系列键值对组成的集合，提供了key到value的映射，在Map中它保证了key与value之间的一一对应关系。也就是说一个key对应一个value，所以它不能存在相同的key值，当然value值可以相同。Map接口中定义了如下常见的方法：

```java
void clear(); //删除Map对象中的所有key-value键值对
boolean containsKey(Object key); //查询Map中是否包含指定的key,如果包含则返回true
boolean containsValue(Object value); //查询Map中是否包含一个或多个value,如果包含则返回true
Set<Map.Entry<K, V>> entrySet(); //返回Map中包含的key-value所组成的Set集合，每个集合元素都是Map.Entry(Entry是Map的内部类)对象
V get(Object key); //返回指定key所对应的value;如果此Map中不包含该key，则返回null
boolean isEmpty();  //查询该Map是否为空
Set<K> keySet(); // 返回该Map中所有key组成的Set集合
V put(K key, V value); //添加一个key-value对，如果当前Map中已经存在一个与该key相等的key-value对，则新的key-value对会覆盖原来的key-value。
void putAll(Map<? extends K, ? extends V> m); //将指定Map中的key-value对复制到该map中
V remove(Object key); //删除指定key锁对应的key-value对，返回被删除key所关联的value,如果该key不存在，则返回null
default boolean remove(Object key, Object value){...}; //删除指定key,value所对应的key-value对
int size(); //返回Map里key-value的个数
Collection<V> values(); //返回该Map里所有value组成的Collection 
boolean equals(Object o); 
int hashCode();
default V getOrDefault(Object key, V defaultValue){...}; //获取指定key对应的value,如果该key不存在，则返回defaulrValue
default void forEach(BiConsumer<? super K, ? super V> action){...}; //使用这个新的API能方便的遍历集合中的元素，这个方法的使用需要结合Lambda表达式：map.forEach((k, v) -> System.out.println("key=" + k + ", value=" + v))
default void replaceAll(BiFunction<? super K, ? super V, ? extends V> function){...};//该方法使用BiFunction对原key-value对进行计算，并将计算结果作为该key-value对的value值。
default V putIfAbsent(K key, V value){...}; //该方法会自动检测指定key对应的value是否为null,如果该key对应的value为null,该方法会用新的value代替原来的null值。调用putIfAbsent会直接插入
default V replace(K key, V value){...}; //将Map中指定key对应的value替换成新value。
default boolean replace(K key, V oldValue, V newValue){...}; //将Map中指定key-value对应的原value替换成新value。如果找到则替换，否则返回false
default V computeIfAbsent(K key, Function<? super K, ? extends V> mappingFunction){...}; //如果传给该方法的key参数在Map中对应的value为null，则使用mappingFunction根据key计算一个新的结果，如果计算结果不为null，则用计算结果覆盖原有的value.如果原Map原来不包含该key，该方法将会添加一组key-value对。
default V computeIfPresent(K key, BiFunction<? super K, ? super V, ? extends V> remappingFunction){...}; //如果传给该方法的key参数在Map中对应的value为null，则使用remappingFunction根据原key,value计算一个新的结果.如果计算结果不为null，则使用该结果覆盖原来的value;如果计算结果为null，则删除原key-value对。
default V compute(K key, BiFunction<? super K, ? super V, ? extends V> remappingFunction){...}; //该方法使用remappingFunction根据原有key-value计算一个新的value.只要新的value不为null,就使用新value覆盖原value；如果原value不为null,但是新value为null,则删除原key-value对；如果原value,新value同时为null,那么直接返回null
default V merge(K key, V value, BiFunction<? super V, ? super V, ? extends V> remappingFunction){...}; //该方法会根据key参数获取在该Map中对应的value。如果获取的value为null,则直接用传入的value覆盖原来的value;如果获取的value不为null,则使用remappingFunction函数根据原value,新value计算一个新的结果，并用得到的结果去覆盖原有的value.

```

我们来看一下Map接口中的内部接口Entry源码，其封装了一个key-value对：

```java
interface Entry<K,V>{
    K getKey(); //返回该Entry里包含的key值
    V getValue(); //返回该Entry里包含的value值
    V setValue(); //设置该Entry里包含的value值，并返回新设置的value值
    boolean equals(Object o);
    int hashCode();
    public static <K extends Comparable<? super K>, V> Comparator<Map.Entry<K,V>> comparingByKey(){
        return (Comparator<Map.Entry<K, V>> & Serializable)
                (c1, c2) -> c1.getKey().compareTo(c2.getKey());
    }

    public static <K, V extends Comparable<? super V>> Comparator<Map.Entry<K,V>> comparingByValue() {
        return (Comparator<Map.Entry<K, V>> & Serializable)
                (c1, c2) -> c1.getValue().compareTo(c2.getValue());
    }

    public static <K, V> Comparator<Map.Entry<K, V>> comparingByKey(Comparator<? super K> cmp) {
        Objects.requireNonNull(cmp);
        return (Comparator<Map.Entry<K, V>> & Serializable)
                (c1, c2) -> cmp.compare(c1.getKey(), c2.getKey());
    }

    public static <K, V> Comparator<Map.Entry<K, V>> comparingByValue(Comparator<? super V> cmp) {
        Objects.requireNonNull(cmp);
        return (Comparator<Map.Entry<K, V>> & Serializable)
                (c1, c2) -> cmp.compare(c1.getValue(), c2.getValue());
    }
}
```

Map接口有三个比较重要的实现类，分别是HashMap、TreeMap和HashTable。在介绍这三个之前，我们先来了解一下Map的抽象类AbstractMap。

#### 1.2.1 AbstractMap源码解析

> AbstractMap抽象类实现了一些简单且通用的方法，本身并不难。但在这个抽象类中有两个方法非常值得关注，keySet和values方法源码的实现可以说是教科书式的典范。Java中Map类型的数据结构有相当多，AbstractMap作为它们的骨架实现实现了Map接口部分方法，也就是说为它的子类各种Map提供了大部分公共的方法，它的子类只需要实现Set<Entry<K,V>> entrySet() 返回一个键值对的集合，就可以使用Map集合的功能了。

抽象类不能通过new关键字直接创建抽象类的实例，但它可以有构造方法。AbstractMap提供了一个protected修饰的无参构造方法，意味着只有它的子类才能访问（当然它本身就是一个抽象类，其他类也不能直接对其实例化），也就是说只有它的子类才能调用这个无参的构造方法。

AbstractMap中唯一的抽象方法：
```java
public abstract Set<Entry<K,V>> entrySet();
```
当我们要实现一个`不可变`的Map时，只需要继承这个类，然后实现entrySet()方法，这个方法返回一保存所有key-value映射的set。通常这个set不支持add(),remove()方法，Set对应的迭代器也不支持remove()方法。

如果想要实现一个可变的Map，我们需要在上述操作外，重写put()方法，因为默认不支持put操作：

```java
public V put(K key, V value) {
        throw new UnsupportedOperationException();
    }
```

而且 entrySet() 返回的 Set 的迭代器，也得实现 remove() 方法，因为 AbstractMap 中的 删除相关操作都需要调用该迭代器的 remove() 方法。

##### AbstractMap的成员变量

```java
/**
 * keySet和values是lazy的，它们只会在第一次请求视图时进行初始化，
 * 而且它们是无状态的，所以只需要一个实例（初始化一次）。
 */
    transient Set<K>        keySet; //保存map中所有的键的Set
    transient Collection<V> values; //保存map中所有值的集合
```

**注意**：这两个成员变量都是被transient修饰的，从jdk1.8开始，这两个变量不再使用volatile修饰，因为调用这两个变量的方法不是同步的，增加volatile也不能保证线程安全。

##### AbstractMap的成员方法

AbstractMap中实现了许多方法，接下来来具体看看AbstractMap中的方法。

**1.添加方法**

```java
    public V put(K key, V value) {
        throw new UnsupportedOperationException();
    }
```
直接抛出异常，如果子类不复写这个方法，那么它是一个不可修改的Map集合。
```java
    public void putAll(Map<? extends K, ? extends V> m) {
        for (Map.Entry<? extends K, ? extends V> e : m.entrySet())
            put(e.getKey(), e.getValue());
    }
```
遍历Map集合m，通过它的entrySet()方法得到可迭代的Set集合，然后将每个键值对存放到本Map集合中。

**2.删除方法**

```java
    public V remove(Object key) {
        //获取键值对的迭代器
        Iterator<Entry<K,V>> i = entrySet().iterator();
        Entry<K,V> correctEntry = null;
        // 根据key是否为null，分成两部分，虽然这两部分代码逻辑几乎一样
        // 这样做主要是减少判断，因为合成一部分的话，判断条件就要增加
        if (key==null) {
            while (correctEntry==null && i.hasNext()) {
                Entry<K,V> e = i.next();
                if (e.getKey()==null)
                    correctEntry = e;
            }
        } else {
            while (correctEntry==null && i.hasNext()) {
                Entry<K,V> e = i.next();
                if (key.equals(e.getKey()))
                    correctEntry = e;
            }
        }

        V oldValue = null;
        //如果找到了这个键值对correctEntry，删除它，并返回它的value值
        if (correctEntry !=null) {
            oldValue = correctEntry.getValue();
            i.remove();
        }
        return oldValue;
    }
```
通过entrySet().iterator()方法，得到键值对的迭代器，然后遍历键值对，找到与key值相等的键值对，删除它，并返回对应的value值，如果没找到，就返回null。

```java
    public void clear() {
        entrySet().clear();
    }
```
调用entrySet集合的clear()方法。

**3.查找元素**

```java
    public boolean containsKey(Object key) {
        Iterator<Map.Entry<K,V>> i = entrySet().iterator();
        if (key==null) {
            while (i.hasNext()) {
                Entry<K,V> e = i.next();
                if (e.getKey()==null)
                    return true;
            }
        } else {
            while (i.hasNext()) {
                Entry<K,V> e = i.next();
                if (key.equals(e.getKey()))
                    return true;
            }
        }
        return false;
    }
```
通过entrySet().iterator()方法，得到键值对的迭代器，然后遍历键值对，找到与key值相等的键值对，返回true，否则返回false。

```java
    public boolean containsValue(Object value) {
        Iterator<Entry<K,V>> i = entrySet().iterator();
        if (value==null) {
            while (i.hasNext()) {
                Entry<K,V> e = i.next();
                if (e.getValue()==null)
                    return true;
            }
        } else {
            while (i.hasNext()) {
                Entry<K,V> e = i.next();
                if (value.equals(e.getValue()))
                    return true;
            }
        }
        return false;
    }
```
通过entrySet().iterator()方法，得到键值对的迭代器，然后遍历键值对，找到与value值相等的键值对，返回true，否则返回false。

```java
    public V get(Object key) {
        Iterator<Entry<K,V>> i = entrySet().iterator();
        if (key==null) {
            while (i.hasNext()) {
                Entry<K,V> e = i.next();
                if (e.getKey()==null)
                    return e.getValue();
            }
        } else {
            while (i.hasNext()) {
                Entry<K,V> e = i.next();
                if (key.equals(e.getKey()))
                    return e.getValue();
            }
        }
        return null;
    }
```
通过entrySet().iterator()方法，得到键值对的迭代器，然后遍历键值对，找到与key值相等的键值对，并返回对应的value值，如果没找到，就返回null。

**4.获取主要的视图**

AbstractMap没有提供entrySet()的实现，但是却提供了keySet()与values()集合视图的默认实现，它们都是依赖于entrySet()返回的集合视图实现的，首先我们来了解一下`public Set<J>keySet()`：

`分析`：该方法返回Map key值的Set集合，很自然的我们可以想到一个简单的实现方案，遍历Entry数组取出key值放到Set集合中，类似下面代码：

```java
//示例代码
public Set<K> keySet() {
    Set<K> ks = null;
    for (Map.Entry<K, V> entry : entrySet()) {
        ks.add(entry.getKey());
    }
    return ks;
}
```
这就意味着每次调用keySet方法都会遍历Entry数组，数据量大时效率会大大降低。不得不说JDK源码是写得非常好，它并没有采取遍历的方式。如果不遍历Entry，那又如何知道此时Map新增了一个key-value键值对呢？

答案就是在keySet方法内部重新实现了一个新的自定义Set集合，在这个自定义Set集合中又重写了iterator方法，这里是关键，iterator方法返回Iterator接口，而在这里又重新实现了Iterator迭代器，通过调用entrySet方法再调用它的iterator方法。下面结合代码来分析：

```java

  /**
   * keySet和values是lazy的，它们只会在第一次请求视图时进行初始化，
   * 而且它们是无状态的，所以只需要一个实例（初始化一次）。
   */
    transient Set<K>        keySet; //保存map中所有的键的Set
    transient Collection<V> values; //保存map中所有的value的Collection

    public Set<K> keySet() {
        Set<K> ks = keySet; //使用keySet变量做缓存，这样只有第一次需要遍历entrySet()集合，对它的操作都调用Map集合对应方法
        if (ks == null) {
            ks = new AbstractSet<K>() { //创建一个自定义Set
                public Iterator<K> iterator() {
                    // 创建一个迭代器，利用 entrySet().iterator()的迭代器来实现本Iterator实例的方法
                    return new Iterator<K>() {
                        private Iterator<Entry<K,V>> i = entrySet().iterator();

                        public boolean hasNext() {
                            return i.hasNext(); //对key值的判断，就是对entry的判断
                        }

                        public K next() {
                            return i.next().getKey(); //取下一个key值，就是取entry#getKey
                        }

                        public void remove() {
                            i.remove(); //删除key值，就是删除entry
                        }
                    };
                }

                public int size() {
                    //key值有多少就是整个Map有多大，所以调用本类的size方法即可。这个是内部类，直接使用this关键字代表这个类，应该指明是调用AbstractMap中的size方法，没有this则表示是static静态方法
                    return AbstractMap.this.size(); 
                }

                public boolean isEmpty() {
                    //对是否有key值，就是判断Map是否为空，，所以调用本类的isEmpty方法即可
                    return AbstractMap.this.isEmpty();
                }

                public void clear() {
                    //清空key值，就是清空Map，，所以调用本类的clear方法即可
                    AbstractMap.this.clear();
                }

                public boolean contains(Object k) {
                    //判断Set是否包含数据k，就是判断Map中是否包含key值，所以调用本类的containsKey方法即可
                    return AbstractMap.this.containsKey(k);
                }
            };
            keySet = ks;
        }
        return ks;
    }
```
这是一种很巧妙的实现，尽管这个方法是围绕key值，但实际上可以结合Entry来实现，而不用遍历Entry，同时上面提到了调用entrySet# iterator方法，这里则又是模板方法模式的最佳实践。因为entrySet在AbstractMap中并未实现，而是交给了它的子类去完成，但是对于keySet方法却可以对它进行一个“算法骨架” 实现，这就是模板方法模式。

下面来看看values()方法的具体实现，其实该方法完全可以参考keySet(),两者有异曲同工之妙，唯一的区别就是返回的是AbstractCollection的子类。

```java
    transient Set<K>        keySet; //保存map中所有的键的Set
    transient Collection<V> values; //保存map中所有的value的Collection

    public Collection<V> values() {
        // 使用values变量做缓存用的，防止每次都遍历创建
        Collection<V> vals = values;
        if (vals == null) {
            // 创建一个Collection集合，对它的操作都调用Map集合对应方法。
            vals = new AbstractCollection<V>() {
                public Iterator<V> iterator() {
                    // 创建一个迭代器，利用 entrySet().iterator()的迭代器来实现本Iterator实例的方法。
                    return new Iterator<V>() {
                        private Iterator<Entry<K,V>> i = entrySet().iterator();

                        public boolean hasNext() {
                            return i.hasNext();
                        }

                        public V next() {
                            return i.next().getValue();
                        }

                        public void remove() {
                            i.remove();
                        }
                    };
                }

                public int size() {
                    return AbstractMap.this.size();
                }

                public boolean isEmpty() {
                    return AbstractMap.this.isEmpty();
                }

                public void clear() {
                    AbstractMap.this.clear();
                }

                public boolean contains(Object v) {
                    return AbstractMap.this.containsValue(v);
                }
            };
            values = vals;
        }
        return vals;
    }
```

**5.AbstractMap中的内部类**

正如 Map 接口 中有内部类 Map.Entry 一样， AbstractMap 也有两个内部类：
- SimpleImmutableEntry, 表示一个不可变的键值对；
- SimpleEntry, 表示可变的键值对。

SimpleImmutableEntry，不可变的键值对,实现了 `Map.Entry <K,V>` 接口和Serializable接口：

```java
    private static boolean eq(Object o1, Object o2) {
        return o1 == null ? o2 == null : o1.equals(o2);
    }

    public static class SimpleImmutableEntry<K,V>
        implements Entry<K,V>, java.io.Serializable
    {
        private static final long serialVersionUID = 7138329143949025153L;

        private final K key; //final修饰，不可变
        private final V value; //final修饰，不可变

        public SimpleImmutableEntry(K key, V value) {
            this.key   = key;
            this.value = value;
        }

        public SimpleImmutableEntry(Entry<? extends K, ? extends V> entry) {
            this.key   = entry.getKey();
            this.value = entry.getValue();
        }

        public K getKey() {
            return key;
        }

        public V getValue() {
            return value;
        }

        // 因为是不可修改键值对Entry类，所以setValue方法直接抛出异常
        public V setValue(V value) {
            throw new UnsupportedOperationException();
        }

        // 当key值与value值都相等时，就说明两个entry值相等
        public boolean equals(Object o) {
            if (!(o instanceof Map.Entry))
                return false;
            Map.Entry<?,?> e = (Map.Entry<?,?>)o; // 因为泛型编译时会被擦除，所以使用?号
            return eq(key, e.getKey()) && eq(value, e.getValue());
        }

        // 保证两个相等的entry，它们的hashCode值必须也相同
        public int hashCode() {
            return (key   == null ? 0 :   key.hashCode()) ^
                   (value == null ? 0 : value.hashCode());
        }

        public String toString() {
            return key + "=" + value;
        }
    }
```

SimpleEntry, 可变的键值对:

```java
    public static class SimpleEntry<K,V>
        implements Entry<K,V>, java.io.Serializable
    {
        private static final long serialVersionUID = -8499721149061103585L;

        private final K key; //不可变
        private V value;

        public SimpleEntry(K key, V value) {
            this.key   = key;
            this.value = value;
        }

        public SimpleEntry(Entry<? extends K, ? extends V> entry) {
            this.key   = entry.getKey();
            this.value = entry.getValue();
        }

        public K getKey() {
            return key;
        }

        public V getValue() {
            return value;
        }

        // 替换value值，并返回原来的oldValue值
        public V setValue(V value) {
            V oldValue = this.value;
            this.value = value;
            return oldValue;
        }

        // 当key值与value值都相等时，就说明两个entry值相等
        public boolean equals(Object o) {
            if (!(o instanceof Map.Entry))
                return false;
            Map.Entry<?,?> e = (Map.Entry<?,?>)o;
            return eq(key, e.getKey()) && eq(value, e.getValue());
        }

        public int hashCode() {
            return (key   == null ? 0 :   key.hashCode()) ^
                   (value == null ? 0 : value.hashCode());
        }

        public String toString() {
            return key + "=" + value;
        }

    }
```

**6.总结**

和 AbstractCollection 接口，AbstractList 接口 作用相似， AbstractMap 是一个基础实现类，实现了 Map 的主要方法，默认不支持修改。常用的几种 Map, 比如 HashMap, TreeMap, LinkedHashMap 都继承自它。
- AbstractMap的核心方法是entrySet()，子类必须实现；
- Entry是存储键值对的数据结构，子类根据Map的特点，构造不同的Entry。

#### 1.2.2 HashMap源码解析(JDK 1.7)

在讨论HashMap具体实现之前，我想我们先了解一下其他数组结构在新增、查找等基础操作时的执行性能：
- 数组：采用一段连续的存储单元来存储数据。对于指定下标的查找，时间复杂度为O(1)；通过给定值进行查找，需要遍历数组，逐一比对给定关键字和数组元素，时间复杂度为O(n)，当然，对于有序数组，则可采用二分查找，插值查找，斐波那契查找等方式，可将查找复杂度提高为O(logn)；对于一般的插入删除操作，涉及到数组元素的移动，其平均复杂度也为O(n)。
- 线性链表：对于链表的新增，删除等操作（在找到指定操作位置后），仅需处理结点间的引用即可，时间复杂度为O(1)，而查找操作需要遍历链表逐一进行比对，复杂度为O(n)。
- 二叉树：对一棵相对平衡的有序二叉树，对其进行插入，查找，删除等操作，平均复杂度均为O(logn)。
- 哈希表：相比上述几种数据结构，在哈希表中进行添加，删除，查找等操作，性能十分之高，不考虑哈希冲突的情况下，仅需一次定位即可完成，时间复杂度为O(1)，接下来我们就来看看哈希表是如何实现达到惊艳的常数阶O(1)的。

我们知道，数据结构的物理存储结构只有两种：顺序存储结构和链式存储结构（像栈，队列，树，图等是从逻辑结构去抽象的，映射到内存中，也这两种物理组织形式），而在上面我们提到过，在数组中根据下标查找某个元素，一次定位就可以达到，哈希表利用了这种特性，哈希表的主干就是数组。

比如我们要新增或查找某个元素，我们通过把当前元素的关键字 通过某个函数映射到数组中的某个位置，通过数组下标一次定位就可完成操作。

**存储位置=f(关键字)**

其中，，这个函数f一般称为哈希函数，这个函数的设计好坏会直接影响到哈希表的优劣。举个例子，比如我们要在哈希表中执行插入操作：

![哈希表插入](https://ws1.sinaimg.cn/large/005CDUpdgy1g61upgsbxmj30sg0i27dt.jpg)

然而万事无完美，如果两个不同的元素，通过哈希函数得出的实际存储地址相同怎么办？也就是说，当我们对某个元素进行哈希运算，得到一个存储地址，然后要进行插入的时候，发现已经被其他元素占用了，其实这就是所谓的`哈希冲突`，也叫哈希碰撞。前面我们提到过，哈希函数的设计至关重要，好的哈希函数会尽可能地保证 计算简单和散列地址分布均匀,但是，我们需要清楚的是，数组是一块连续的固定长度的内存空间，再好的哈希函数也不能保证得到的存储地址绝对不发生冲突。那么哈希冲突如何解决呢？哈希冲突的解决方案有多种:开放定址法（发生冲突，继续寻找下一块未被占用的存储地址），再散列函数法，链地址法，而HashMap在JDK 1.7中就是采用了链地址法，也就是数组+链表的方式。(在Java 1.8中采用了数组+链表+红黑树的方式)

**下面我们先来分析JDK 1.7版本的HashMap源码：**

参考文章：

[Java：手把手带你源码分析 HashMap 1.7](https://blog.csdn.net/carson_ho/article/details/79373026)

[Java1.7 HashMap 实现原理和源码分析](https://www.cnblogs.com/zsh-blogs/p/10453646.html)

##### 1.类定义

```java
public class HashMap<K,V>
         extends AbstractMap<K,V> 
         implements Map<K,V>, Cloneable, Serializable

```
![主要介绍](https://ws1.sinaimg.cn/large/005CDUpdgy1g61uzg4mb9j30yg0f4gpz.jpg)

##### 2.数据结构

HashMap采用的数据结构是：数组(主)+单链表(副)，该数据结构描述又被称之为`拉链法`:

对于数组(主)，其主要的作用如下：
- 核心底层 = 1个数组(table[]),其又被称之为核心数组；
- 数组下标 = 经过处理的键Key的hash值(通过hashCode() 计算等一系列处理)
- 数组元素 = 1个键值对 = 1个链表(头节点)
- 数组大小 = HashMap的容量 (capacity)

而对于单链表(副)：
- 每个链表 = 哈希表的桶(bucket)
- 链表的节点值 = 1个键值对
- 链表长度 = 桶的大小
- 链表主要是用于解决哈希冲突：若是不同key值计算出来的hash值相同(即都存储到了数组的相同位置)，由于之前该hash值的数组位置已经存放好元素，则将原先位置的元素移到单链表中，冲突hash值对应的键值对放入到数组元素中。(**即发生冲突时，新元素插入到链表头部；新元素总是添加到数组中，旧元素移到链表中**)
- 采用链表解决hash冲突的方法 = 链地址法
  
**Attention**: HashMap的键值对数量 = 数组的键值对 + 所有单链表的键值对

给出示意图如下所示：

![示意图](https://ws1.sinaimg.cn/large/005CDUpdgy1g61vcekvtaj30i20a0q3u.jpg)

给出粗略的存储流程如下：

![存储流程](https://ws1.sinaimg.cn/large/005CDUpdgy1g61vdntpt1j30fa0rs75a.jpg)

**数组元素、链表节点的实现类**

HashMap中的数组元素采用Entry静态内部类实现，如下所示：

![HashMap整体结构](https://ws1.sinaimg.cn/large/005CDUpdgy1g61vh53b14j30sg0kok3m.jpg)

> 1. HashMap的本质 =  1个存储Entry类对象的数组 + 多个单链表
> 2. Entry对象本质 = 1个映射（键 - 值对），属性包括：键（key）、值（value） & 下1节点( next) = 单链表的指针 = 也是一个Entry对象，用于解决hash冲突

给出该类的源码：
```java
    static class Entry<K,V> implements Map.Entry<K,V> {
        final K key; //键
        V value;  // 值
        Entry<K,V> next; // 指向下一个节点 ，也是一个Entry对象，从而形成解决hash冲突的单链表
        int hash; //对key的hashcode值进行hash运算后得到的值，存储在Entry，避免重复计算

        /**
         * Creates new entry.
         */
        Entry(int h, K k, V v, Entry<K,V> n) {
            value = v;
            next = n;
            key = k;
            hash = h;
        }

        public final K getKey() {
            return key;
        }

        public final V getValue() {
            return value;
        }

        public final V setValue(V newValue) {
            V oldValue = value;
            value = newValue;
            return oldValue;
        }

       //作用：判断2个Entry是否相等，必须key和value都相等，才返回true  
        public final boolean equals(Object o) {
            if (!(o instanceof Map.Entry))
                return false;
            Map.Entry e = (Map.Entry)o;
            Object k1 = getKey();
            Object k2 = e.getKey();
            if (k1 == k2 || (k1 != null && k1.equals(k2))) {
                Object v1 = getValue();
                Object v2 = e.getValue();
                if (v1 == v2 || (v1 != null && v1.equals(v2)))
                    return true;
            }
            return false;
        }

        public final int hashCode() {
            return Objects.hashCode(getKey()) ^ Objects.hashCode(getValue());
        }

        public final String toString() {
            return getKey() + "=" + getValue();
        }

        /**
         * This method is invoked whenever the value in an entry is
         * overwritten by an invocation of put(k,v) for a key k that's already
         * in the HashMap.
         */
        void recordAccess(HashMap<K,V> m) {
        }

        /**
         * This method is invoked whenever the entry is
         * removed from the table.
         */
        void recordRemoval(HashMap<K,V> m) {
        }
    }
```

##### 3.HashMap中的重要变量

主要参数其实包括： 容量、负载因子和扩容阈值。
```java

// 1. 容量（capacity）： HashMap中数组的长度
// a. 容量范围：必须是2的幂 & <最大容量（2的30次方）
// b. 初始容量 = 哈希表创建时的容量
    
    // 默认容量为16
    static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16

    //最大的容量，为2的30次方
    static final int MAXIMUM_CAPACITY = 1 << 30;

// 2. 负载因子(Load factor)：HashMap在其容量自动增加前可达到多满的一种尺度
// a. 负载因子越大、填满的元素越多 = 空间利用率高、但冲突的机会加大、查找效率变低（因为链表变长了）
// b. 负载因子越小、填满的元素越少 = 空间利用率小、冲突的机会减小、查找效率高（链表不长)

    //默认加载因子
    static final float DEFAULT_LOAD_FACTOR = 0.75f;

    //实际加载因子
    final float loadFactor;

    //当数组还没有进行扩容操作的时候，共享的一个空表对象
    static final Entry<?,?>[] EMPTY_TABLE = {};

    //table,进行扩容操作，长度必须2的n次方
    transient Entry<K,V>[] table = (Entry<K,V>[]) EMPTY_TABLE;

    //HashMap的大小，即 HashMap中存储的键值对的数量
    transient int size;

// 3. 扩容阈值（threshold）：当哈希表的大小 ≥ 扩容阈值时，就会扩容哈希表（即扩充HashMap的容量） 
// a. 扩容 = 对哈希表进行resize操作（即重建内部数据结构），从而哈希表将具有大约两倍的桶数
// b. 扩容阈值 = 容量 x 加载因子

    //阈值，用于判断是否需要扩容（threshold = 容量*负载因子）
    int threshold;

    //HashMap改变的次数
    transient int modCount;

    static final int ALTERNATIVE_HASHING_THRESHOLD_DEFAULT = Integer.MAX_VALUE;
```

![参数示意图](https://ws1.sinaimg.cn/large/005CDUpdgy1g61vzzwto9j30jg0a4wf4.jpg)

详细地介绍一下负载因子的使用建议：

![加载因子](https://ws1.sinaimg.cn/large/005CDUpdgy1g61w13v0lcj30rz0indhg.jpg)

##### 4.源码分析

为了更具体的了解源码，从具体的使用步骤进行相关函数的详细分析，其主要内容如下所示：

![分析内容](https://ws1.sinaimg.cn/large/005CDUpdgy1g61w3hhnz0j30ku0fvmzm.jpg)

**1. 构造函数**

```java
    //指定“容量大小”和“加载因子”的构造函数
    public HashMap(int initialCapacity, float loadFactor) {
        if (initialCapacity < 0)
            throw new IllegalArgumentException("Illegal initial capacity: " +
                                               initialCapacity);
        if (initialCapacity > MAXIMUM_CAPACITY)
            initialCapacity = MAXIMUM_CAPACITY;
        if (loadFactor <= 0 || Float.isNaN(loadFactor))
            throw new IllegalArgumentException("Illegal load factor: " +
                                               loadFactor);

        this.loadFactor = loadFactor; //设置加载因子
        // 设置 扩容阈值 = 初始容量
        // 注：此处不是真正的阈值，是为了扩展table，该阈值后面会重新计算，下面会详细讲解 
        threshold = initialCapacity; 
        init();  // 一个空方法用于未来的子对象扩展
    }

    // 指定“容量大小”的构造函数,加载因子 = 默认 = 0.75 、容量 = 指定大小
    public HashMap(int initialCapacity) {
        this(initialCapacity, DEFAULT_LOAD_FACTOR);
    }

      /**
     * 构造函数1：默认构造函数（无参）
     * 加载因子 & 容量 = 默认 = 0.75、16
     */
    public HashMap() {
        // 实际上是调用构造函数3：指定“容量大小”和“加载因子”的构造函数
        // 传入的指定容量 & 加载因子 = 默认
        this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR); 
    }

    // 包含“子Map”的构造函数,即 构造出来的HashMap包含传入Map的映射关系
    // 加载因子 & 容量 = 默认
    public HashMap(Map<? extends K, ? extends V> m) {
        // 设置容量大小 & 加载因子 = 默认
        this(Math.max((int) (m.size() / DEFAULT_LOAD_FACTOR) + 1,
                      DEFAULT_INITIAL_CAPACITY), DEFAULT_LOAD_FACTOR);

        // 该方法用于初始化 数组 & 阈值，下面会详细说明
        inflateTable(threshold);

        // 将传入的子Map中的全部元素逐个添加到HashMap中
        putAllForCreate(m);
    }

```
注意：
- 此处仅用于接收初始容量大小（capacity）、加载因子(Load factor)，但仍无真正初始化哈希表，即初始化存储数组table；
- **真正初始化哈希表（初始化存储数组table）是在第1次添加键值对时，即第1次调用put（）时。**下面会详细说明。

**2. put()方法的解析**

给出一个添加数据的流程图：

![添加数据](https://ws1.sinaimg.cn/large/005CDUpdgy1g61wfmfqwkj30fa0rs3zi.jpg)

```java
    public V put(K key, V value) {
        // (分析1) 1.若未初始化哈希表，即table为空
        // 则使用构造函数设置的阈值(即初始容量)来初始化数组table
        if (table == EMPTY_TABLE) {
            inflateTable(threshold);
        }

        //(分析2) 2.判断key是否为空值null
        // 2.1 若key == null，则将该键-值 存放到数组table 中的第1个位置，即table [0]（本质：key = Null时，hash值 = 0，故存放到table[0]中）
        // 该位置永远只有1个value，新传进来的value会覆盖旧的value
        if (key == null)
            return putForNullKey(value);

        // (分析3) 2.2 若 key ≠ null，则计算存放数组 table 中的位置（下标、索引）
        // a. 根据key值计算hash值
        int hash = hash(key);
        // b. 根据hash值 最终获得key对应存放的数组Table中位置
        int i = indexFor(hash, table.length);

        // 3. 判断该key对应的值是否已存在（通过遍历 以该数组元素为头结点的链表 逐个判断）
        for (Entry<K,V> e = table[i]; e != null; e = e.next) {
            Object k;
            // (分析4) 3.1 若该key已存在（即 key-value已存在 ），则用 新value 替换 旧value
            if (e.hash == hash && ((k = e.key) == key || key.equals(k))) {
                V oldValue = e.value;
                e.value = value;
                e.recordAccess(this);
                return oldValue; //返回旧的value
            }
        }

        modCount++;

        //（分析5） 3.2 若 该key不存在，则将“key-value”添加到table中
        addEntry(hash, key, value, i);
        return null;
    }
```

根据源码做出相对应的流程图如下：

![put流程](https://ws1.sinaimg.cn/large/005CDUpdgy1g61wpej3yzj30yg0qdgnl.jpg)

下面针对源码里标明的5个分析点进行详细解释：

1. 初始化哈希表(即初始化数组table, 扩容阈值)

```java
//函数使用原型
if (table == EMPTY_TABLE) {
    inflateTable(threshold);
}

//源码分析

    private void inflateTable(int toSize) {
        // 将传入的容量大小转化为：>传入容量大小的最小的2的次幂，即如果传入的是容量大小是19，那么转化后，初始化容量大小为32（即2的5次幂）
        int capacity = roundUpToPowerOf2(toSize);

        //重新计算阈值 threshold = 容量 * 加载因子
        threshold = (int) Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1);

        // 使用计算后的初始容量（已经是2的次幂） 初始化数组table（作为数组长度）,即 哈希表的容量大小 = 数组大小（长度）
        table = new Entry[capacity];
        
        //修改hashSeed 
        initHashSeedAsNeeded(capacity);
    }

    // 将传入的容量大小转化为：>传入容量大小的最小的2的幂
    // 特别注意：容量大小必须为2的幂，该原因在下面的讲解会详细分析
    private static int roundUpToPowerOf2(int number) {
        // 若 容量超过了最大值，初始化容量设置为最大值 ；否则，设置为：>传入容量大小的最小的2的次幂
        return number >= MAXIMUM_CAPACITY
                ? MAXIMUM_CAPACITY
                : (number > 1) ? Integer.highestOneBit((number - 1) << 1) : 1;
    }

    // 与虚拟机设置有关，改变hashSeed的值
    final boolean initHashSeedAsNeeded(int capacity) {
        boolean currentAltHashing = hashSeed != 0;
        boolean useAltHashing = sun.misc.VM.isBooted() &&
                (capacity >= Holder.ALTERNATIVE_HASHING_THRESHOLD);
        boolean switching = currentAltHashing ^ useAltHashing;
        if (switching) {
            hashSeed = useAltHashing
                ? sun.misc.Hashing.randomHashSeed(this)
                : 0;
        }
        return switching;
    }

```
通过上面分析可以看出：**真正初始化哈希表（初始化存储数组table）是在第1次添加键值对时，即第1次调用put（）时**。

2. 当 key == null时，将该 key-value 的存储位置规定为数组table 中的第1个位置，即table [0].

```java
//函数使用原型
if (key == null)
    return putForNullKey(value);

// 源码分析

    private V putForNullKey(V value) {
        // 遍历以table[0]为首的链表，寻找是否存在key==null 对应的键值对
        // 1. 若有：则用新value 替换 旧value；同时返回旧的value值
        for (Entry<K,V> e = table[0]; e != null; e = e.next) {
            if (e.key == null) {
                V oldValue = e.value;
                e.value = value;
                e.recordAccess(this);
                return oldValue;
            }
        }
        modCount++;

        // 2. 若无key==null的键，那么调用addEntry（），将空键 & 对应的值封装到Entry中，并放到table[0]中
        addEntry(0, null, value, 0);
        // 注：
    // a. addEntry（）的第1个参数 = hash值 = 传入0
    // b. 即 说明：当key = null时，也有hash值 = 0，所以HashMap的key 可为null
    // c. 对比HashTable，由于HashTable对key直接hashCode（），若key为null时，会抛出异常，所以HashTable的key不可为null
    // d. 此处只需知道是将 key-value 添加到HashMap中即可，关于addEntry（）的源码分析将等到下面再详细说明，
        return null;
    }
```
从此处可以看出：
- HashMap的键key 可为null（区别于 HashTable的key 不可为null）；
- HashMap的键key 可为null且只能为1个，但值value可为null且为多个

3. 计算存放数组 table 中的位置（即 数组下标 or 索引）

```java
//函数使用原型
int hash = hash(key); // a. 根据键值key计算hash值 ->> 分析1
int i = indexFor(hash, table.length); // b. 根据hash值 最终获得 key对应存放的数组Table中位置 ->> 分析2

//源码分析

    //将 键key 转换成 哈希码（hash值）操作  = 使用hashCode() + 4次位运算 + 5次异或运算（9次扰动）
    final int hash(Object k) {
        int h = hashSeed;
        if (0 != h && k instanceof String) {
            return sun.misc.Hashing.stringHash32((String) k);
        }

        h ^= k.hashCode();

        h ^= (h >>> 20) ^ (h >>> 12);
        return h ^ (h >>> 7) ^ (h >>> 4);
    }


    static int indexFor(int h, int length) {
        // assert Integer.bitCount(length) == 1 : "length must be a non-zero power of 2";
        return h & (length-1); //将对哈希码扰动处理后的结果 与运算(&) （数组长度-1），最终得到存储在数组table的位置（即数组下标、索引）
    }
```

![数组下标计算过程](https://ws1.sinaimg.cn/large/005CDUpdgy1g61x91y901j30nm0b1dhh.jpg)

在了解了如何计算存放数组table 中的位置 后，所谓**知其然而需知其所以然**，下面将讲解为什么要这样计算，即主要解答以下3个问题：
- 为什么不直接采用经过hashCode()处理的哈希码 作为存储数组table的下标位置？
- 为什么采用哈希码 与运算(&) （数组长度-1） 计算数组下标？
- 为什么在计算数组下标前，需对哈希码进行二次处理：扰动处理？

在回答这3个问题前，有一个核心思想需要了解：
> 所有处理的根本目的，都是为了提高 存储key-value的数组下标位置 的随机性 & 分布均匀性，尽量避免出现hash值冲突。即：对于不同key，存储的数组下标位置要尽可能不一样。

**问题1：为什么不直接采用经过hashCode（）处理的哈希码 作为 存储数组table的下标位置？**

这是因为如果采用这种方式，容易出现 哈希码 与 数组大小范围不匹配的情况，即 计算出来的哈希码可能 不在数组大小范围内，从而导致无法匹配存储位置。

![原因描述](https://ws1.sinaimg.cn/large/005CDUpdgy1g61xf1x8jhj30yg0asgp4.jpg)

为了解决 “哈希码与数组大小范围不匹配” 的问题，HashMap给出了解决方案：哈希码 与运算（&） （数组长度-1）。

**问题2： 为什么采用 哈希码 与运算(&) （数组长度-1） 计算数组下标？**

根据HashMap的容量大小（数组长度），按需取 哈希码一定数量的低位 作为存储的数组下标位置，从而 解决 “哈希码与数组大小范围不匹配” 的问题

![具体原因描述](https://ws1.sinaimg.cn/large/005CDUpdgy1g61xifotumj30yg0hpdmt.jpg)

上图同时也给出了为什么HashMap的数组长度一定是2的次幂问题的解答，其实还有一个原因，将在后面具体讲述。

**问题3： 为什么在计算数组下标前，需对哈希码进行二次处理：扰动处理？**

该操作是为了加大哈希码低位的随机性，使得分布更均匀，从而提高对应数组存储下标位置的随机性 & 均匀性，最终减少Hash冲突。

![原因描述](https://ws1.sinaimg.cn/large/005CDUpdgy1g61xkuymsij30yg0cw0vm.jpg)

4. 若对应的key已存在，则 使用 新value 替换 旧value

> 当发生 Hash冲突时，为了保证 键key的唯一性哈希表并不会马上在链表中插入新数据，而是先查找该 key是否已存在，若已存在，则替换即可.

```java
   /**
     * 函数使用原型
     */
// 2. 判断该key对应的值是否已存在（通过遍历 以该数组元素为头结点的链表 逐个判断）
        for (Entry<K,V> e = table[i]; e != null; e = e.next) {
            Object k;
            // 2.1 若该key已存在（即 key-value已存在 ），则用 新value 替换 旧value
            if (e.hash == hash && ((k = e.key) == key || key.equals(k))) {
                V oldValue = e.value;
                e.value = value;
                e.recordAccess(this);
                return oldValue; //并返回旧的value
            }
        }

        modCount++;

        // 2.2 若 该key不存在，则将“key-value”添加到table中
        addEntry(hash, key, value, i);
        return null;

```
此处无复杂的源码分析，但此处的分析点主要有2个：替换流程 & key是否存在（即key值的对比）

**替换流程**

![替换流程](https://ws1.sinaimg.cn/large/005CDUpdgy1g61xo1judsj30ji18vmza.jpg)

**key值的对比**

采用 equals（） 或 “==” 进行比较，下面给出其介绍 & 与 “==”使用的对比：

![key值比较](https://ws1.sinaimg.cn/large/005CDUpdgy1g61xpimbdmj30y608ctah.jpg)

5. 若对应的key不存在，则将该“key-value”添加到数组table的对应位置中

```java
//函数使用原型
2.2 若 该key不存在，则将“key-value”添加到table中
addEntry(hash, key, value, i);

//源码解析

    void addEntry(int hash, K key, V value, int bucketIndex) {
        // 1.插入前，先判断容量是否足够
        // 1.1 若不足够，则进行扩容(2倍)、重新计算Hash值、重新计算数组存储下标
        if ((size >= threshold) && (null != table[bucketIndex])) {
            resize(2 * table.length); // a.扩容两倍 --》分析1
            hash = (null != key) ? hash(key) : 0; // b. 重新计算该Key对应的Hash值
            bucketIndex = indexFor(hash, table.length); // c. 重新计算该Key对应的hash值的存储数组下标位置
        }

        // 1.2 若容量足够，则创建1个新的数组元素（Entry） 并放入到数组中 --》 分析2
        createEntry(hash, key, value, bucketIndex);
    }

    void resize(int newCapacity) {
        //1.保存旧数组（old table）
        Entry[] oldTable = table;
        //2.保存旧容量（old capacity ），即数组长度
        int oldCapacity = oldTable.length;
        //3.若旧容量已经是系统默认最大容量了，那么将阈值设置成整型的最大值，退出  
        if (oldCapacity == MAXIMUM_CAPACITY) {
            threshold = Integer.MAX_VALUE;
            return;
        }
        // 4. 根据新容量（2倍容量）新建1个数组，即新table
        Entry[] newTable = new Entry[newCapacity];
        // 5. 将旧数组上的数据（键值对）转移到新table中，从而完成扩容 ->>分析1.1 
        transfer(newTable, initHashSeedAsNeeded(newCapacity));
        // 6. 新数组table引用到HashMap的table属性上
        table = newTable;
        // 7. 重新设置阈值
        threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);
    }

    /**
      * 分析1.1：transfer(newTable); 
      * 作用：将旧数组上的数据（键值对）转移到新table中，从而完成扩容
      * 过程：按旧链表的正序遍历链表、在新链表的头部依次插入
    */
    void transfer(Entry[] newTable, boolean rehash) {
        // 获取新数组的大小 = 获取新容量大小 
        int newCapacity = newTable.length;
        for (Entry<K,V> e : table) { //通过遍历 旧数组，将旧数组上的数据（键值对）转移到新数组中
            while(null != e) {
                Entry<K,V> next = e.next; //遍历 以该数组元素为首 的链表,转移链表时，因是单链表，故要保存下1个结点，否则转移后链表会断开
                if (rehash) {
                    e.hash = null == e.key ? 0 : hash(e.key);
                }
                int i = indexFor(e.hash, newCapacity);
                //将当前entry的next链指向新的索引位置,newTable[i]有可能为空，有可能也是个entry链，如果是entry链，直接在链表头部插入。
                // 扩容后，可能出现逆序：按旧链表的正序遍历链表、在新链表的头部依次插入
                e.next = newTable[i];
                newTable[i] = e;
                // 访问下1个Entry链上的元素，如此不断循环，直到遍历完该链表上的所有节点
                e = next;
            }
        }
    }

    // 若容量足够，则创建1个新的数组元素（Entry） 并放入到数组中
    void createEntry(int hash, K key, V value, int bucketIndex) {
        // 把table中该位置原来的Entry保存 
        Entry<K,V> e = table[bucketIndex];

        // 2. 在table中该位置新建一个Entry：将原头结点位置（数组上）的键值对 放入到（链表）后1个节点中、将需插入的键值对 放入到头结点中（数组上）-> 从而形成链表
        // 即 在插入元素时，是在链表头插入的，table中的每个位置永远只保存最新插入的Entry，旧的Entry则放入到链表中（即 解决Hash冲突）
        table[bucketIndex] = new Entry<>(hash, key, value, e);
        size++;
    }
```
此处有2点需要特别注意的：**键值对的添加方式与扩容机制**

**键值对的添加方式：单链表的头插法**

即将该位置（数组上）原来的数据放在该位置的（链表）下1个节点中（next）、在该位置（数组上）放入需插入的数据-> 从而形成链表。

![键值对添加方式](https://ws1.sinaimg.cn/large/005CDUpdgy1g62hz6ycr0j30ji18vwgt.jpg)

**扩容机制**

来看一下具体流程：

![扩容流程](https://ws1.sinaimg.cn/large/005CDUpdly1g62i10umtdj30ee186tb1.jpg)

扩容过程中的转移数据示意图：

![数据转移](https://ws1.sinaimg.cn/large/005CDUpdly1g62i20rijoj30wn23an2p.jpg)

在扩容resize()过程中，在将旧数组上的数据 转移到 新数组上时，转移操作 = 按旧链表的正序遍历链表、在新链表的头部依次插入，即在转移数据、扩容后，容易出现链表逆序的情况.

> 设重新计算存储位置后不变，即扩容前 = 1->2->3，扩容后 = 3->2->1

此外，此时若（多线程）并发执行 put()操作，一旦出现扩容情况，则容易出现环形链表，从而在获取数据、遍历链表时形成死循环（Infinite Loop）。在此，就直接给出`为什么HashMap是线程不安全的原因`：

- `put的时候导致的多线程数据不一致`。这个问题比较好想象，比如有两个线程A和B，首先A希望插入一个key-value对到HashMap中，首先计算记录所要落到的桶的索引坐标，然后获取到该桶里面的链表头结点，此时线程A的时间片用完了，而此时线程B被调度得以执行，和线程A一样执行，只不过线程B成功将记录插到了桶里面，假设线程A插入的记录计算出来的桶索引和线程B要插入的记录计算出来的桶索引是一样的，那么当线程B成功插入之后，线程A再次被调度运行时，它依然持有过期的链表头但是它对此一无所知，以至于它认为它应该这样做，如此一来就覆盖了线程B插入的记录，这样线程B插入的记录就凭空消失了，造成了数据不一致的行为。
- `多线程并发执行put()操作时，可能因为resize()操作出现环形链表，从而引起死循环`。

**给出形成环形链表的具体分析流程：**

![多线程HashMap的resize](https://ws1.sinaimg.cn/large/005CDUpdgy1g62ie5fhigj312k0hgdhn.jpg)

我们假设有两个线程同时需要执行resize操作，我们原来的桶数量为2，记录数为3，需要resize桶到4，原来的记录分别为：[3,A],[7,B],[5,C]，在原来的map里面，我们发现这三个entry都落到了第二个桶里面。

假设线程thread1执行到了transfer方法的Entry next = e.next这一句，然后时间片用完了，此时的e = [3,A], next = [7,B]。线程thread2被调度执行并且顺利完成了resize操作，需要注意的是，此时的[7,B]的next为[3,A]。此时线程thread1重新被调度运行，此时的thread1持有的引用是已经被thread2 resize之后的结果。线程thread1首先将[3,A]迁移到新的数组上，然后再处理[7,B]，而[7,B]被链接到了[3,A]的后面，处理完[7,B]之后，就需要处理[7,B]的next了啊，而通过thread2的resize之后，[7,B]的next变为了[3,A]，此时，[3,A]和[7,B]形成了环形链表，后面继续遍历那么就会陷入死循环。

**前面提到HashMap的数组长度为什么一定是2的次幂的一些原因，其实在resize这里还有另外一种解释：**

hashMap的数组长度一定保持2的次幂，比如16的二进制表示为 10000，那么length-1就是15，二进制为01111，同理扩容后的数组长度为32，二进制表示为100000，length-1为31，二进制表示为011111。从下图可以我们也能看到这样会保证低位全为1，而扩容后只有一位差异，也就是多出了最左位的1，这样在通过 h&(length-1)的时候，只要h对应的最左边的那一个差异位为0，就能保证得到的新的数组索引和老数组索引一致(大大减少了之前已经散列良好的老数组的数据位置重新调换)

![求余操作](https://ws1.sinaimg.cn/large/005CDUpdgy1g62ij7trkyj30p20ek0ub.jpg)

还有，数组长度保持2的次幂，length-1的低位都为1，会使得获得的数组索引index更加均匀，比如：

![均匀](https://ws1.sinaimg.cn/large/005CDUpdgy1g62ik8n4msj30r40cc75o.jpg)

我们看到，上面的&运算，高位是不会对结果产生影响的（hash函数采用各种位运算可能也是为了使得低位更加散列），我们只关注低位bit，如果低位全部为1，那么对于h低位部分来说，任何一位的变化都会对结果产生影响，也就是说，要得到index=21这个存储位置，h的低位只有这一种组合。这也是数组长度设计为必须为2的次幂的原因。

![非全1](https://ws1.sinaimg.cn/large/005CDUpdgy1g62il31j2ej30r00d6dit.jpg)

如果不是2的次幂，也就是低位不是全为1此时，要使得index=21，h的低位部分不再具有唯一性了，哈希冲突的几率会变的更大，同时，index对应的这个bit位无论如何不会等于1了，而对应的那些数组位置也就被白白浪费了。

6. 总结

向 HashMap 添加数据（成对 放入 键 - 值对）的全流程：

![put全流程](https://ws1.sinaimg.cn/large/005CDUpdgy1g62injydpij30yg139gp5.jpg)

示意图：

![示意图](https://ws1.sinaimg.cn/large/005CDUpdgy1g62iodx8jxj30yg13qtdv.jpg)

**3. get()方法的解析**

给出get()方法的流程如下：

![get()](https://ws1.sinaimg.cn/large/005CDUpdgy1g62iqb0g40j30hs0oqjst.jpg)

```java
    public V get(Object key) {
        if (key == null) // 1.当key == null时，则到 以哈希表数组中的第1个元素（即table[0]）为头结点的链表去寻找对应 key == null的键
            return getForNullKey(); //分析1

        // 2. 当key ≠ null时，去获得对应值 -->分析2
        Entry<K,V> entry = getEntry(key);

        return null == entry ? null : entry.getValue();
    }

    // 当key == null时，则到 以哈希表数组中的第1个元素（即table[0]）为头结点的链表去寻找对应 key == null的键
    private V getForNullKey() {
        if (size == 0) {
            return null;
        }
        for (Entry<K,V> e = table[0]; e != null; e = e.next) {
            if (e.key == null)
                return e.value;
        }
        return null;
    }

    final Entry<K,V> getEntry(Object key) {
        if (size == 0) {
            return null;
        }

        // 1. 根据key值，通过hash（）计算出对应的hash值
        int hash = (key == null) ? 0 : hash(key);
        for (Entry<K,V> e = table[indexFor(hash, table.length)];
             e != null;
             e = e.next) { // 遍历 以该数组下标的数组元素为头结点的链表所有节点，寻找该key对应的值
            Object k;
            if (e.hash == hash &&
                ((k = e.key) == key || (key != null && key.equals(k))))
                return e;
        }
        return null;
    }
```

**4. 其他常用方法的解析**

HashMap除了核心的put（）、get（）函数，还有以下主要使用的函数方法：

```java
void clear(); // 清除哈希表中的所有键值对
int size();  // 返回哈希表中所有 键值对的数量 = 数组中的键值对 + 链表中的键值对
boolean isEmpty(); // 判断HashMap是否为空；size == 0时 表示为 空 

void putAll(Map<? extends K, ? extends V> m);  // 将指定Map中的键值对 复制到 此Map中
V remove(Object key);  // 删除该键值对

boolean containsKey(Object key); // 判断是否存在该键的键值对；是 则返回true
boolean containsValue(Object value);  // 判断是否存在该值的键值对；是 则返回true
```

下面将简单介绍上面几个函数的源码分析:

```java
  /**
   * 函数：isEmpty()
   * 作用：判断HashMap是否为空，即无键值对；size == 0时 表示为 空 
   */

public boolean isEmpty() {  
    return size == 0;  
} 

 /**
   * 函数：size()
   * 作用：返回哈希表中所有 键值对的数量 = 数组中的键值对 + 链表中的键值对
   */

   public int size() {  
    return size;  
}  

 /**
   * 函数：clear()
   * 作用：清空哈希表，即删除所有键值对
   * 原理：将数组table中存储的Entry全部置为null、size置为0
   */ 
public void clear() {  
    modCount++;  
    Arrays.fill(table, null);
    size = 0;
}  

/**
   * 函数：putAll(Map<? extends K, ? extends V> m)
   * 作用：将指定Map中的键值对 复制到 此Map中
   * 原理：类似Put函数
   */ 

    public void putAll(Map<? extends K, ? extends V> m) {  
    // 1. 统计需复制多少个键值对  
    int numKeysToBeAdded = m.size();  
    if (numKeysToBeAdded == 0)  
        return; 

    // 2. 若table还没初始化，先用刚刚统计的复制数去初始化table  
    if (table == EMPTY_TABLE) {  
        inflateTable((int) Math.max(numKeysToBeAdded * loadFactor, threshold));  
    }  
  
    // 3. 若需复制的数目 > 阈值，则需先扩容 
    if (numKeysToBeAdded > threshold) {  
        int targetCapacity = (int)(numKeysToBeAdded / loadFactor + 1);  
        if (targetCapacity > MAXIMUM_CAPACITY)  
            targetCapacity = MAXIMUM_CAPACITY;  
        int newCapacity = table.length;  
        while (newCapacity < targetCapacity)  
            newCapacity <<= 1;  
        if (newCapacity > table.length)  
            resize(newCapacity);  
    }  
    // 4. 开始复制（实际上不断调用Put函数插入）  
    for (Map.Entry<? extends K, ? extends V> e : m.entrySet())  
        put(e.getKey(), e.getValue());
}  

 /**
   * 函数：remove(Object key)
   * 作用：删除该键值对
   */ 

public V remove(Object key) {  
    Entry<K,V> e = removeEntryForKey(key);  
    return (e == null ? null : e.value);  
}  
  
final Entry<K,V> removeEntryForKey(Object key) {  
    if (size == 0) {  
        return null;  
    }  
    // 1. 计算hash值
    int hash = (key == null) ? 0 : hash(key);  
    // 2. 计算存储的数组下标位置
    int i = indexFor(hash, table.length);  
    Entry<K,V> prev = table[i];  
    Entry<K,V> e = prev;  
  
    while (e != null) {  
        Entry<K,V> next = e.next;  
        Object k;  
        if (e.hash == hash &&  
            ((k = e.key) == key || (key != null && key.equals(k)))) {  
            modCount++;  
            size--; 
            // 若删除的是table数组中的元素（即链表的头结点） 
            // 则删除操作 = 将头结点的next引用存入table[i]中  
            if (prev == e) 
                table[i] = next;

            //否则 将以table[i]为头结点的链表中，当前Entry的前1个Entry中的next 设置为 当前Entry的next（即删除当前Entry = 直接跳过当前Entry）
            else  
                prev.next = next;   
            e.recordRemoval(this);  
            return e;  
        }  
        prev = e;  
        e = next;  
    }  
  
    return e;  
} 

 /**
   * 函数：containsKey(Object key)
   * 作用：判断是否存在该键的键值对；是 则返回true
   * 原理：调用get（），判断是否为Null
   */
   public boolean containsKey(Object key) {  
    return getEntry(key) != null; 
} 

 /**
   * 函数：containsValue(Object value)
   * 作用：判断是否存在该值的键值对；是 则返回true
   */   
public boolean containsValue(Object value) {  
    // 若value为空，则调用containsNullValue()  
    if (value == null)
        return containsNullValue();  
    
    // 若value不为空，则遍历链表中的每个Entry，通过equals（）比较values 判断是否存在
    Entry[] tab = table;
    for (int i = 0; i < tab.length ; i++)  
        for (Entry e = tab[i] ; e != null ; e = e.next)  
            if (value.equals(e.value)) 
                return true;//返回true  
    return false;  
}  
  
// value为空时调用的方法  
private boolean containsNullValue() {  
    Entry[] tab = table;  
    for (int i = 0; i < tab.length ; i++)  
        for (Entry e = tab[i] ; e != null ; e = e.next)  
            if (e.value == null)
                return true;  
    return false;  
} 
```



##### 5.与JDK1.8的区别

HashMap 的实现在 JDK 1.7 和 JDK 1.8 差别较大，具体区别如下：

**1. 数据结构**

![数据结构](https://ws1.sinaimg.cn/large/005CDUpdgy1g62j4hsuh6j30yg09i423.jpg)

**2.获取数据过程**

![数据获取过程](https://ws1.sinaimg.cn/large/005CDUpdgy1g62j55qt3pj30x207swg7.jpg)

**3.扩容机制**

![扩容机制](https://ws1.sinaimg.cn/large/005CDUpdgy1g62j8rmqoej30uk078gn2.jpg)

##### 6.关于HashMap的其他问题

**1. HashMap如何解决Hash冲突？**

![Hash冲突解决](https://ws1.sinaimg.cn/large/005CDUpdgy1g62ja9taafj30yg0jbn1j.jpg)

**2. 为什么HashMap具备下述特点：键-值（key-value）都允许为空、线程不安全、不保证有序、存储位置随时间变化?**

![HashMap特点](https://ws1.sinaimg.cn/large/005CDUpdgy1g62jbe1tzuj30wa0f8dh2.jpg)

**3.为什么 HashMap 中 String、Integer 这样的包装类适合作为 key 键？**

![HashMap键的选择](https://ws1.sinaimg.cn/large/005CDUpdgy1g62jcirm7dj30yg0agjtj.jpg)

**4.HashMap 中的 key若 Object类型， 则需实现哪些方法？**

![Object类型](https://ws1.sinaimg.cn/large/005CDUpdgy1g62jdkwoobj30yg0cntav.jpg)


#### 1.2.3 HashMap源码分析(JDK 1.8)

HashMap的设计就是为了在查找获得最优的性能(希望基本获取O(1)的时间复杂度),因此HashMap主要使用了数组作为核心的数据存储的结构，同时使用链地址法解决K-V映射时产生的碰撞，在Java8中同时加入红黑树来优化碰撞时数据匹配的性能。下面，我将通过分析源码，讲解HashMap1.8相对应JDK 1.7版本的更新内容。

##### 1.类声明

```java
public class HashMap<K,V> extends AbstractMap<K,V> implements Map<K,V>, Cloneable, Serializable
```
HashMap继承自AbstractMap，实现了Map接口，Map接口定义了所有Map子类必须实现的方法。AbstractMap也实现了Map接口，并且提供了两个实现Entry的内部类：SimpleEntry和SimpleImmutableEntry。其具体介绍与JDK 1.7一样。

##### 2.数据结构

主要的数据结构介绍如下：

![jdk1.8数据结构](https://ws1.sinaimg.cn/large/005CDUpdly1g647z912bkj30lx0jzmxy.jpg)

红黑树(R-B Tree,即Red-Black Tree),是一种特殊的二叉查找数，其主要有以下特点：
- 每个节点的颜色 = 黑色/红色，其根节点为黑色，空叶子节点为黑色；
- 父、子节点必须是不同颜色；
- 从1个节点到该节点的子孙节点的所有路径上包含相同数量的黑色节点。(确保了没有1条路径会比其他路径长出2倍，因此，红黑树是相对接近于平衡二叉树)；
- 其时间复杂度为O(log n)。

给出一个粗略的存储流程如下所示：

![1.jpg](https://i.loli.net/2019/08/26/OeFTuwSpQl5hjaE.png)

在JDK 1.8中，HashMap中的数组元素与链表节点采用了Node类来实现(1.7中是Entry类，内容没什么变化)，给出其源码如下所示：

```java
/** 
  * Node  = HashMap的内部类，实现了Map.Entry接口，本质是 = 一个映射(键值对)
  * 实现了getKey()、getValue()、equals(Object o)和hashCode()等方法
  **/
    static class Node<K,V> implements Map.Entry<K,V> {
        final int hash;
        final K key;
        V value;
        Node<K,V> next;

        Node(int hash, K key, V value, Node<K,V> next) {
            this.hash = hash;
            this.key = key;
            this.value = value;
            this.next = next;
        }

        public final K getKey()        { return key; }
        public final V getValue()      { return value; }
        public final String toString() { return key + "=" + value; }

        public final int hashCode() {
            return Objects.hashCode(key) ^ Objects.hashCode(value);
        }

        public final V setValue(V newValue) {
            V oldValue = value;
            value = newValue;
            return oldValue;
        }

        public final boolean equals(Object o) {
            if (o == this)
                return true;
            if (o instanceof Map.Entry) {
                Map.Entry<?,?> e = (Map.Entry<?,?>)o;
                if (Objects.equals(key, e.getKey()) &&
                    Objects.equals(value, e.getValue()))
                    return true;
            }
            return false;
        }
    }
```

JDK1.8中引入了红黑树，其在源码中的具体实现类是TreeNode,简略给出源码如下：

```java
    static final class TreeNode<K,V> extends LinkedHashMap.Entry<K,V> {
        TreeNode<K,V> parent;  // red-black tree links
        TreeNode<K,V> left;
        TreeNode<K,V> right;
        TreeNode<K,V> prev;    // needed to unlink next upon deletion
        boolean red;
        TreeNode(int hash, K key, V val, Node<K,V> next) {
            super(hash, key, val, next);
        }

        /**
         * Returns root of tree containing this node.
         */
        final TreeNode<K,V> root() {
            for (TreeNode<K,V> r = this, p;;) {
                if ((p = r.parent) == null)
                    return r;
                r = p;
            }
        }

        ...
    }
```

##### 3.HashMap中的重要变量

HashMap中的主要参数与JDK 1.7中大致相同(包含容量、加载因子和扩容阈值)。但是由于其数据结构加入了红黑树，因此也加入了与红黑树相关的属性。具体如下所示：

```java
    /**
     * The default initial capacity - MUST be a power of two.
     */
    static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16

    /**
     * The maximum capacity, used if a higher value is implicitly specified
     * by either of the constructors with arguments.
     * MUST be a power of two <= 1<<30.
     */
    static final int MAXIMUM_CAPACITY = 1 << 30;

    /**
     * 默认加载因子
     */
    static final float DEFAULT_LOAD_FACTOR = 0.75f;

    /**
     * 存储数据的Node类型 数组，长度 = 2的幂；数组的每个元素 = 1个单链表
     */
    transient Node<K,V>[] table;

    /**
     * Holds cached entrySet(). Note that AbstractMap fields are used
     * for keySet() and values().
     */
    transient Set<Map.Entry<K,V>> entrySet;

    /**
     * HashMap中存储的键值对的数量
     */
    transient int size;

    //HashMap改变的次数
    transient int modCount;

       // 3. 扩容阈值（threshold）：当哈希表的大小 ≥ 扩容阈值时，就会扩容哈希表（即扩充HashMap的容量） 
      // a. 扩容 = 对哈希表进行resize操作（即重建内部数据结构），从而哈希表将具有大约两倍的桶数
      // b. 扩容阈值 = 容量 x 加载因子

    int threshold;

    //实际加载因子
    final float loadFactor;

    // 桶的树化阈值：即将链表转成红黑树的阈值，在存储数组时，当链表长度大于该值时，则将链表转换成红黑树
    static final int TREEIFY_THRESHOLD = 8;

    // 桶的链表还原阈值：即红黑树转化为链表的阈值，当在扩容时(此时HashMap的数据存储位置会重新计算)，在重新计算存储位置后，
    // 当原有的红黑树内数量 < 6时，则将红黑树转化成链表
    static final int UNTREEIFY_THRESHOLD = 6;

    // 最小树形化容量阈值：即当哈希表中的容量大于该值时，才允许树形化链表(即将链表转化为红黑树)
    // 否则，若桶内元素太多时，则直接扩容，而不是树形化
    // 为了避免进行扩容、树形化选择的冲突，这个值不能小于 4*TREEIFY_THRESHOLD
    static final int MIN_TREEIFY_CAPACITY = 64;
```

为此，我们来总结一下HashMap的数据结构与参数在JDK1.8与JDK 1.7之间的异同点：

<table>
    <tr>
        <th>版本</th>
        <th>存储的数据结构</th>
        <th>数组&链表节点的实现类</th>
        <th>红黑树的实现类</th>
        <th>核心参数</th>
    </tr>
    <tr>
        <td>JDK 1.8</td>
        <td>数组+链表+红黑树</td>
        <td>Node类</td>
        <td>TreeNode类</td>
        <td rowspan="2">主要参数相同 = 容量、加载因子、扩容阈值。但是JDK1.8增设了与红黑树相关的参数： <br>1. 桶的树化阈值<br>即将链表转化为红黑树的阈值，在存储数据时，当链表长度大于该值时，即将链表转换为红黑树<br>2.桶的链表还原阈值<br>即将红黑树转为链表的阈值，当在扩容时(此时HashMap的数据存储位置会重新计算)，在重新计算存储位置后，当原有的红黑树内数量小于6时，则将红黑树转换成链表<br>3.最小树形化容量阈值<br>即当哈希表中的容量大于该值时，才允许树形化链表。否则，若桶内元素太多时，则直接扩容，而不是树形化。为了避免直接扩容、树形化选择的冲突，这个值不能小于4*TREEIFY_THRESHOLD</td>
    </tr>
    <tr>
        <td>JDK 1.7</td>
        <td>数组+链表</td>
        <td>Entry类</td>
        <td>/</td>
    </tr>
</table>

##### 4.源码分析

为了更具体的了解源码，从具体的使用步骤进行相关函数的详细分析，其主要内容如下所示：

![详细分析](https://i.loli.net/2019/08/26/wHVqfBM317p2gNr.png)

**1.构造函数**

```java

    // 构造函数1：指定“容量大小”和“加载因子”的构造函数
    // 加载因子 & 容量 = 自己指定
    public HashMap(int initialCapacity, float loadFactor) {
        if (initialCapacity < 0)
            throw new IllegalArgumentException("Illegal initial capacity: " +
                                               initialCapacity);
        if (initialCapacity > MAXIMUM_CAPACITY)
            initialCapacity = MAXIMUM_CAPACITY;
        // 填充比必须为正 
        if (loadFactor <= 0 || Float.isNaN(loadFactor))
            throw new IllegalArgumentException("Illegal load factor: " +
                                               loadFactor);
        this.loadFactor = loadFactor;
        // 设置 扩容阈值
        // 注：此处不是真正的阈值，仅仅只是将传入的容量大小转化为：>传入容量大小的最小的2的幂，该阈值后面会重新计算
        // 下面会详细讲解 ->> 分析1
        this.threshold = tableSizeFor(initialCapacity);
    }

    // 构造函数2：指定“容量大小”的构造函数
    // 加载因子 = 默认 = 0.75 、容量 = 指定大小
    public HashMap(int initialCapacity) {
        this(initialCapacity, DEFAULT_LOAD_FACTOR);
    }

    // 构造函数3： 默认构造函数（无参）
    public HashMap() {
        this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted
    }

    // 构造函数4：包含“子Map”的构造函数
    // 即 构造出来的HashMap包含传入Map的映射关系
    // 加载因子 & 容量 = 默认
    public HashMap(Map<? extends K, ? extends V> m) {
        this.loadFactor = DEFAULT_LOAD_FACTOR;
        putMapEntries(m, false);
    }

    // 分析1：tableSizeFor(initialCapacity)
    // 作用：将传入的容量大小转化为：>传入容量大小的最小的2的幂
    static final int tableSizeFor(int cap) {
        int n = cap - 1;
        n |= n >>> 1;
        n |= n >>> 2;
        n |= n >>> 4;
        n |= n >>> 8;
        n |= n >>> 16;
        return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
    }
```

> 同JDK 1.7类似，这里仅用于接收初始容量大小(Capacity)、加载因子(Load Factor)，但仍无真正初始化哈希表，即初始化存储数组table。**真正初始化哈希表是在第一次添加键值对时，也就是第一次调用put()方法时。**

我们来分析一下`tableSizeFor()`方法，HashMap构造函数允许用户传入的容量不是2的n次方，因为它可以自动地将传入的容量转换为 2 的 n 次方。

先来考虑如何求一个数的掩码，对于10010000，它的掩码为11111111，可以使用下面方法得到：

```
mask = mask >> 1   11011000
mask = mask >> 2   11110110
mask = mask >> 4   11111111
```
mask+1是大于原始数字的最小的2的n次方。

```
num   10010000
mask+1 100000000
```
综合对比`tableSizeFor`方法的实现，我们也就能够明白这个方法的功能了。

**2.put()方法的解析**

对于该put()方法，其具体实现与JDK 1.7差别较大：

![put过程的异同](https://i.loli.net/2019/08/26/XW2Ns9vugdhyoI1.png)

给出一个JDK 1.8的添加数据的简易流程图，如下所示：

![存储流程图](https://i.loli.net/2019/08/26/89oekIsTJBvjpaq.png)

```java
    public V put(K key, V value) {
        //1. 对传人数组的键key计算hash值  ->> 分析1
        //2. 再调用putVal()添加数据进去   ->> 分析2
        return putVal(hash(key), key, value, false, true);
    }
```

下面，针对上面的两个分析点进行讲解：

1. hash(key):确定哈希桶数组索引位置

```java
   /**
     * 分析1：hash(key)
     * 作用：计算传入数据的哈希码（哈希值、Hash值）
     * 该函数在JDK 1.7 和 1.8 中的实现不同，但原理一样 = 扰动函数 = 使得根据key生成的哈希码（hash值）分布更加均匀、更具备随机性，避免出现hash值冲突（即指不同key但生成同1个hash值）
     * JDK 1.7 做了9次扰动处理 = 4次位运算 + 5次异或运算
     * JDK 1.8 简化了扰动函数 = 只做了2次扰动 = 1次位运算 + 1次异或运算
     */

    //JDK 1.8实现：将键key转换成hash值操作 = 使用hashCode() + 1次位运算 + 1次异或运算(2次扰动)
    // 1. 取hashCode值： h = key.hashCode()
    // 2. 高位参与低位的运算： h ^ (h >>> 16)
    static final int hash(Object key) {
        int h;
        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
        // a. 当key = null时，hash值 = 0，所以HashMap的key 可为null      
        // 注：对比HashTable，HashTable对key直接hashCode（），若key为null时，会抛出异常，所以HashTable的key不可为null
        // b. 当key ≠ null时，则通过先计算出 key的 hashCode()（记为h），然后 对哈希码进行 扰动处理： 按位 异或（^） 哈希码自身右移16位后的二进制
    }

    //JDK 1.7实现： 将键key转换成哈希码（hash值）操作  = 使用hashCode() + 4次位运算 + 5次异或运算（9次扰动）
    static final int hash(int h) {
        h ^= k.hashCode(); 
        h ^= (h >>> 20) ^ (h >>> 12);
        return h ^ (h >>> 7) ^ (h >>> 4);
    }

    /**
     * 计算存储位置的函数分析：indexFor(hash, table.length)
     * 注：该函数仅存在于JDK 1.7 ，JDK 1.8中实际上无该函数（直接用1条语句判断写出），但原理相同
     * 为了方便讲解，故提前到此讲解
     */

    static int indexFor(int h, int length) {  
        // 将对哈希码扰动处理后的结果 与运算(&) （数组长度-1），最终得到存储在数组table的位置（即数组下标、索引）
        return h & (length-1);  
    }

```

根据上面的源码对比分析，我们来总结一下计算存放在table数组中位置的过程：

![位置计算](https://i.loli.net/2019/08/26/3bQyUBiMWFoGkvT.png)

在JDK 1.8中优化了高位运算的算法，通过hashCode()的高16位异或低16位实现的：`(h = k.hashCode()) ^ (h >>> 16)`，主要是从速度、功效、质量来考虑的，这么做可以在数组table的length比较下的时候，也能保证考虑到高低位Bit都参与到Hash的计算中，同时不会有很大的开销。下面给出一个例子说明一下：

![计算示意图](https://i.loli.net/2019/08/26/T9WuxaFLo5pmDtX.png)

在了解了如何计算存放数组table 中的位置 后，所谓**知其然而需知其所以然**，下面将讲解为什么要这样计算，即主要解答以下3个问题：
- 为什么不直接采用经过hashCode()处理的哈希码 作为存储数组table的下标位置？
- 为什么采用哈希码 与运算(&) （数组长度-1） 计算数组下标？
- 为什么在计算数组下标前，需对哈希码进行二次处理：扰动处理？

在回答这3个问题前，有一个核心思想需要了解：
> 所有处理的根本目的，都是为了提高 存储key-value的数组下标位置 的随机性 & 分布均匀性，尽量避免出现hash值冲突。即：对于不同key，存储的数组下标位置要尽可能不一样。

**问题1：为什么不直接采用经过hashCode（）处理的哈希码 作为 存储数组table的下标位置？**

这是因为如果采用这种方式，容易出现 哈希码 与 数组大小范围不匹配的情况，即 计算出来的哈希码可能 不在数组大小范围内，从而导致无法匹配存储位置。

![哈希码取值](https://i.loli.net/2019/08/26/jPtGRC9zMlABwSU.png)

**问题2： 为什么采用 哈希码 与运算(&) （数组长度-1） 计算数组下标？**

根据HashMap的容量大小（数组长度），按需取 哈希码一定数量的低位 作为存储的数组下标位置，从而 解决 “哈希码与数组大小范围不匹配” 的问题。

![原因描述](https://i.loli.net/2019/08/26/wQhrAJVH2WT7DeF.png)

**问题3： 为什么在计算数组下标前，需对哈希码进行二次处理：扰动处理？**

该操作是为了加大哈希码低位的随机性，使得分布更均匀，从而提高对应数组存储下标位置的随机性 & 均匀性，最终减少Hash冲突。

![原因描述](https://i.loli.net/2019/08/26/jzoBEZNhMxQHf4Y.png)

2. putVal(hash(key),key,value,false,true)

对于putVal方法，其主要有两个部分需要讲解：其一是计算完存储位置之后，具体该如何将数据存放到哈希表中；其二就是扩容的机制。

**2.1计算完存储位置，数据如何存入哈希表中**

由于数据结构中加入了红黑树，所以在存放数据到哈希表中时，需要进行多次数据结构的判断：`数组、红黑树、链表`。下面给出一个具体的判断流程图：

![插入数据流程分析](https://i.loli.net/2019/08/26/Y6wT9yHlp5kAE3V.png)

```java
    /**
     * 分析2：putVal(hash(key), key, value, false, true)
     */
    final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                   boolean evict) {
        Node<K,V>[] tab; Node<K,V> p; int n, i;
        // 1. 如果哈希表的数组是空，则通过resize()创建。所以，初始化哈希表的时机 = 第1次调用put函数时，即调用resize()初始化创建
        if ((tab = table) == null || (n = tab.length) == 0)
            n = (tab = resize()).length;

        // 2. 计算插入存储的数组索引i：根据key值计算的hash值得到
        // 此处的数组下标计算方式 = i = (n - 1) & hash，同JDK 1.7中的indexFor（），上面已详细描述

        //3. 插入时，需要判断hash值是否存在冲突：
        // 首先，若不存在(即table[i] == null),则直接在该数组位置新建节点，插入完毕
        // 否则，代表存在hash冲突，即当前存储位置已经存在节点，则依次往下判断： a. 当前位置的key是否与需要插入的key相同； b. 判断需要插入的数据结构是否为红黑树或者链表


        if ((p = tab[i = (n - 1) & hash]) == null)
            tab[i] = newNode(hash, key, value, null);  // 不存在的情况，newNode(hash, key, value, null)的源码 = new Node<>(hash, key, value, next)
        else {
            Node<K,V> e; K k;

            // a.判断table[i]的元素的key是否与插入的key一样，如果相同，则直接用新的value覆盖旧的value,判断原则equals()
            if (p.hash == hash &&
                ((k = p.key) == key || (key != null && key.equals(k))))
                e = p;
            // b. 继续判断：需要插入的数据结构是否为红黑树或者链表
            // 如果为红黑树的话，则直接在树中插入 Or 更新键值对
            else if (p instanceof TreeNode)
                e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);  // ->>分析3
            // 若是链表，则在链表中插入 Or 更新键值对
            // i. 遍历table[i],判断key是否已经存在：采用equals()对比当前遍历节点的key与需要插入数据的key：若已存在，则直接用新value覆盖旧value
            // ii. 遍历完毕后仍无发现上述所说的情况，则直接在链表尾部插入数据
            // 但是，注意：新增节点后，需要判断链表长度是否大于8 (8 = 桶的树化阈值) ： 若是，则把链表转换为红黑树
            else {
                
                for (int binCount = 0; ; ++binCount) {
                    // 对于ii: 若数组的下一个位置，表示已经到表尾也没有找到key值相同节点，则新建节点 = 插入节点
                    // 注：此处是从链表尾部插入，与JDK 1.7不同(JDK 1.7是从链表头部插入，即永远都是添加到数组的位置，原来数组位置的数据则往后移) 
                    if ((e = p.next) == null) {
                        p.next = newNode(hash, key, value, null);
                        // 插入节点后，若链表节点大于阈值，则将链表转换为红黑树
                        if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                            treeifyBin(tab, hash); //树化操作
                        break;
                    }

                    // 对于i: 
                    if (e.hash == hash &&
                        ((k = e.key) == key || (key != null && key.equals(k))))
                        break;
                    
                    //更新p指向下一个节点，继续遍历
                    p = e;
                }
            }

            // 对后续情况的操作：发现key已经存在，直接用新value覆盖旧value & 返回旧value
            if (e != null) { // existing mapping for key
                V oldValue = e.value;
                // onlyIfAbsent表示是否仅在oldValue为null的情况下更新键值对的值
                if (!onlyIfAbsent || oldValue == null)
                    e.value = value;
                afterNodeAccess(e);  //替换旧值时会调用的方法(默认实现为空)
                return oldValue;
            }
        }
        ++modCount;

        //插入成功后，判断实际存在的键值对size > 最大容量threshold
        // 若大于，则进行扩容 --> 分析4
        if (++size > threshold)
            resize();
        afterNodeInsertion(evict); // 插入成功时会调用的方法（默认实现为空）
        return null;
    }

        /**
         * 分析3： putTreeVal(this,tab,hash,key,value)
         * 作用:向红黑树中插入 or 更新数据
         * 过程： 遍历红黑树判断该节点
         */
        final TreeNode<K,V> putTreeVal(HashMap<K,V> map, Node<K,V>[] tab,
                                       int h, K k, V v) {
            Class<?> kc = null;
            boolean searched = false;
            TreeNode<K,V> root = (parent != null) ? root() : this;
            for (TreeNode<K,V> p = root;;) {
                int dir, ph; K pk;
                if ((ph = p.hash) > h)
                    dir = -1;
                else if (ph < h)
                    dir = 1;
                else if ((pk = p.key) == k || (k != null && k.equals(pk)))
                    return p;
                else if ((kc == null &&
                          (kc = comparableClassFor(k)) == null) ||
                         (dir = compareComparables(kc, k, pk)) == 0) {
                    if (!searched) {
                        TreeNode<K,V> q, ch;
                        searched = true;
                        if (((ch = p.left) != null &&
                             (q = ch.find(h, k, kc)) != null) ||
                            ((ch = p.right) != null &&
                             (q = ch.find(h, k, kc)) != null))
                            return q;
                    }
                    dir = tieBreakOrder(k, pk);
                }

                TreeNode<K,V> xp = p;
                if ((p = (dir <= 0) ? p.left : p.right) == null) {
                    Node<K,V> xpn = xp.next;
                    TreeNode<K,V> x = map.newTreeNode(h, k, v, xpn);
                    if (dir <= 0)
                        xp.left = x;
                    else
                        xp.right = x;
                    xp.next = x;
                    x.parent = x.prev = xp;
                    if (xpn != null)
                        ((TreeNode<K,V>)xpn).prev = x;
                    moveRootToFront(tab, balanceInsertion(root, x));
                    return null;
                }
            }
        }
```

给出一个具体的插入流程总结如下图所示：

![具体数据插入流程](https://i.loli.net/2019/08/26/jptSeED9l7UnXVa.png)


**2.2扩容机制(resize()方法)**

首先，给出扩容流程如下：

![扩容流程](https://i.loli.net/2019/08/26/1ma9gnIO4Z58UXr.png)

源码分析：

```java
    /**
     * 分析4：resize（）
     * 该函数有2种使用情况：1.初始化哈希表 2.当前数组容量过小，需扩容
     */
    final Node<K,V>[] resize() {
        Node<K,V>[] oldTab = table; //扩容前的数组(当前数组)
        int oldCap = (oldTab == null) ? 0 : oldTab.length; //扩容前的数组的容量 = 长度
        int oldThr = threshold; // 扩容前数组的阈值
        int newCap, newThr = 0;

        //针对情况2
        if (oldCap > 0) {
            // 若table容量超过容量最大值，则不再扩容，只将阀值设置为最大
            if (oldCap >= MAXIMUM_CAPACITY) {
                threshold = Integer.MAX_VALUE;
                return oldTab;
            }
            //若无超过最大值，就扩充为原来的2倍
            else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
                     oldCap >= DEFAULT_INITIAL_CAPACITY)
                newThr = oldThr << 1; // double threshold
        }
        //针对情况1：如果当前表是空的，但是有阈值。代表是初始化时指定了容量、阈值的情况
        else if (oldThr > 0) // initial capacity was placed in threshold
            newCap = oldThr;
        else {               // zero initial threshold signifies using defaults
        //如果当前表是空的，而且也没有阈值。代表是初始化时没有任何容量/阈值参数的情况  
            newCap = DEFAULT_INITIAL_CAPACITY;
            newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
        }
        if (newThr == 0) {
            //如果新的阈值是0，对应的是  当前表是空的，但是有阈值的情况
            float ft = (float)newCap * loadFactor; //根据新表容量 和 加载因子 求出新的阈值
            //进行越界修复
            newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?
                      (int)ft : Integer.MAX_VALUE);
        }
        //更新阈值
        threshold = newThr;
        @SuppressWarnings({"rawtypes","unchecked"})
        //根据新的容量 构建新的哈希桶
            Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
        //更新哈希桶引用
        table = newTab;
        //如果以前的哈希桶中有元素
        //下面开始将当前哈希桶中的所有节点转移到新的哈希桶中
        if (oldTab != null) {
            //遍历老的哈希桶
            for (int j = 0; j < oldCap; ++j) {
                //取出当前的节点 e
                Node<K,V> e;
                //如果当前桶中有元素，则将链表赋值给e
                if ((e = oldTab[j]) != null) {
                    //将原哈希桶置空以便GC
                    oldTab[j] = null;
                    // 如果当前链表就只有一个元素(没有发生哈希碰撞)
                    if (e.next == null)
                        newTab[e.hash & (newCap - 1)] = e; //直接将这个元素放置在新的哈希桶里。注意这里去下标使用哈希值 & 新的桶长度-1. 由于桶的长度是2的n次方，这么做其实是等于 一个模运算。但是效率更高
                    // 如果发生哈希碰撞，并且节点数超过了8个转换成为了红黑树时，在重新映射，需要对红黑树进行拆分
                    else if (e instanceof TreeNode)
                        ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
                    // 如果发生过哈希碰撞，节点数小于8个。则要根据链表上每个节点的哈希值，依次放入新哈希桶对应下标位置。
                    else { // preserve order
                        // 因为扩容是容量翻倍，所以原来链表上的每个节点，现在可能存放在原来的下标，即low位，或者扩容后的下标，即high位。high位= low位 + 原哈希桶容量 
                        Node<K,V> loHead = null, loTail = null; //低位链表的头尾节点
                        Node<K,V> hiHead = null, hiTail = null; //高位链表的头尾节点
                        Node<K,V> next; //临时节点，存放e的下一个节点
                        do {
                            next = e.next;
                            // 利用位运算代替常规运算：利用哈希值与旧的容量，可以得到哈希值去模后，是大于等于oldCap还是小于oldCap，等于0代表小于oldCap，应该存放在低位，否则放在高位
                            if ((e.hash & oldCap) == 0) {
                                //给头尾节点指针赋值
                                if (loTail == null)
                                    loHead = e;
                                else
                                    loTail.next = e;
                                loTail = e;
                            }
                            else {
                                //高位也是相同的逻辑
                                if (hiTail == null)
                                    hiHead = e;
                                else
                                    hiTail.next = e;
                                hiTail = e;
                            }//循环直到链表结束
                        } while ((e = next) != null);
                        // 将低位链表存放在原index处
                        if (loTail != null) {
                            loTail.next = null;
                            newTab[j] = loHead;
                        }
                        //将高位链表存放在新index处
                        if (hiTail != null) {
                            hiTail.next = null;
                            newTab[j + oldCap] = hiHead;
                        }
                    }
                }
            }
        }
        return newTab;
    }
```
结合上面分析的源码，我们给出扩容流程图如下：

![扩容流程对比图](https://i.loli.net/2019/08/26/pb4Gy5ndiMNQZI1.png)

在JDK 1.8中，扩容过程中重新映射需要考虑节点类型。对于树形节点，需先拆分红黑树再映射。对于链表类型节点，则需要先对链表进行分组，然后再映射。需要注意的是，分组后，组内节点相对位置保持不变。我们先来看看链表是如何进行分组映射的。

我们都知道往底层数据结构中插入节点时，一般都是先通过模运算计算桶位置，接着把节点放入桶中即可。事实上我们可以把重新映射看做插入操作。在JDK 1.7中，也确实是这样做的。但在JDK 1.8中，则对这个过程进行了一定的优化，逻辑上要稍微复杂一点。在详细分析之前，我们先来回顾一下求余的过程：

![15160962033713.jpg](https://i.loli.net/2019/08/26/VCL1ZFmw4tlhMHk.jpg)

上图中，桶数组大小 = 16,hash1与hash2不相等。但因为只有后4位参与求余，所以结果相等。当桶数组扩容后，n由16变成了32，对上面hash值重新进行映射：

![15160965715169.jpg](https://i.loli.net/2019/08/26/cU1isH9NCTJOMyY.jpg)

扩容后，参与模运算的位数由4位变成了5位。由于两个hash第5位的值是不一样，所以两个hash算出来的结果也不一样。上面的计算过程并不难理解继续往下分析。

![15162009417224.jpg](https://i.loli.net/2019/08/26/nvCNED3GYlqModx.jpg)

假设我们上图的桶数组进行扩容，扩容后容量n = 16,重新映射过程如下：依次遍历链表，并计算节点`hash & oldCap`的值。如下图所示：

![1.jpg](https://i.loli.net/2019/08/26/fQcZnBPvmgFSwEL.jpg)

如果值为0，将loHead和loTail的值指向这个节点。如果后面还有节点`hash & oldCap`为0的话，则将节点链入loHead指向的链表中，并将loTail指向该节点。如果值为非0的话，则让hiHead和hiTail指向该节点。完成遍历后，可能会得到两条链表。此时就完成了链表分组：

![链表分组](https://i.loli.net/2019/08/26/Jjc98unzDNsKFSZ.jpg)

最后，再将这两条链表存放到对应的桶中，完成扩容。如下图所示：

![扩容完成](https://i.loli.net/2019/08/26/g9BErxId12swLkX.jpg)

从上图可以发现，重新映射后，两条链表中的节点顺序并未发生变化，还是保持了扩容前的顺序。以上就是 JDK 1.8 中 HashMap 扩容的代码讲解。另外再补充一下，JDK 1.8 版本下 HashMap 扩容效率要高于之前版本。如果大家看过 JDK 1.7 的源码会发现，JDK 1.7 为了防止因 hash 碰撞引发的拒绝服务攻击，在计算 hash 过程中引入随机种子。以增强 hash 的随机性，使得键值对均匀分布在桶数组中。在扩容过程中，相关方法会根据容量判断是否需要生成新的随机种子，并重新计算所有节点的 hash。而在 JDK 1.8 中，则通过引入红黑树替代了该种方式。从而避免了多次计算 hash 的操作，提高了扩容效率。

为此，我们可以来总结一下JDK 1.87扩容时数据存储位置重新计算的方式：

![计算结论](https://i.loli.net/2019/08/26/KjWCB8VIkDGLfyN.png)

给出其结论总结示意图如下：

![结论示意图](https://i.loli.net/2019/08/26/G7ps8xaFDoMNyvk.png)

3. 链表树化、红黑树链化与拆分

JDK 1.8对HashMap实现进行了改进，最大的改进莫过于引入了红黑树处理频繁的碰撞，代码复杂度也随之上升。比如，以前只需要实现一套针对链表操作的方法即可。而引入红黑树后，则需要另外实现红黑树相关的操作。为此，我们就来分析putVal()方法中所提到的相关红黑树操作。首先，我们先来看看**树化**的相关代码：

```java
    // 将普通节点链表转换成树形节点链表
    final void treeifyBin(Node<K,V>[] tab, int hash) {
        int n, index; Node<K,V> e;
        //当桶数组容量小于MIN_TREEIFY_CAPACITY，优先进行扩容而不是树化
        if (tab == null || (n = tab.length) < MIN_TREEIFY_CAPACITY)
            resize();
        else if ((e = tab[index = (n - 1) & hash]) != null) {
            //hd为头节点，tl为尾结点
            TreeNode<K,V> hd = null, tl = null;
            do {
                //将普通节点替换成树形节点
                TreeNode<K,V> p = replacementTreeNode(e, null);
                if (tl == null)
                    hd = p;
                else {
                    p.prev = tl;
                    tl.next = p;
                }
                tl = p;
            } while ((e = e.next) != null);  // 将普通链表转换成树形节点链表
            if ((tab[index] = hd) != null)
                hd.treeify(tab); // 将树形链表转换成红黑树
        }
    }

    // For treeifyBin
    TreeNode<K,V> replacementTreeNode(Node<K,V> p, Node<K,V> next) {
        return new TreeNode<>(p.hash, p.key, p.value, next);
    }
```
在扩容过程中，树化要满足两个条件：
- 链表长度大于等于TREEIFY_THRESHOLD
- 桶数组容量大于等于MIN_TREEIFY_CAPACITY

对于第二个条件的原因，看到一个比较合理的介绍：当桶数组容量比较小时，键值对节点 hash 的碰撞率可能会比较高，进而导致链表长度较长。这个时候应该优先扩容，而不是立马树化。毕竟高碰撞率是因为桶数组容量较小引起的，这个是主因。容量小时，优先扩容可以避免一些列的不必要的树化过程。同时，桶容量较小时，扩容会比较频繁，扩容时需要拆分红黑树并重新映射。所以在桶容量比较小的情况下，将长链表转成红黑树是一件吃力不讨好的事。

我们继续来看一下`treeifyBin方法`，该方法主要的作用是将普通链表转换成为由TreeNode节点组成的链表，并在最后调用treeify是将该链表转为红黑树。TreeNode继承自Node类，所以TreeNode仍然包含next引用，原链表的节点顺序最终通过next引用被保存下来。我们假设在树化之前，链表结构如下所示：

![数化之前链表结构](https://i.loli.net/2019/08/26/vSb8JImChgkrfsD.jpg)

HashMap在设计之初，并没有考虑到以后会引入红黑树进行优化。所以并没有像TreeMap那样，要求键类实现comparable接口或者提供相应的比较器。但由于树化过程中需要比较两个键对象的大小，在键类没有实现comparable接口的情况下，怎么比较键与键之间的大小就成了一个棘手的问题。为了解决这个问题，HashMap是做了三步处理的明确可以比较出两个键的大小：
- 比较键与键之间hash的大小，如果hash相同，继续往下比较
- 检测键类是否实现了Comparable接口，如果实现调用compareTo方法进行比较
- 如果仍未比较出大小，就需要进行仲裁了，仲裁方法为tieBreakOrder方法。

通过上面三次比较，最终就可以比较出孰大孰小。比较出大小后就可以构造红黑树了，最终构造出的红黑树如下所示：

![红黑树结构](https://i.loli.net/2019/08/26/ers7PhvAQbxDl1j.jpg)

橙色的箭头表示 TreeNode 的 next 引用。由于空间有限，prev 引用未画出。可以看出，链表转成红黑树后，原链表的顺序仍然会被引用仍被保留了（红黑树的根节点会被移动到链表的第一位），我们仍然可以按遍历链表的方式去遍历上面的红黑树。这样的结构为后面红黑树的切分以及红黑树转成链表做好了铺垫，我们继续往下分析。

**红黑树拆分**

扩容后，普通节点需要重新映射，红黑树也不例外。按照一般的思路，我们可以先把红黑树转成链表，之后再重新映射链表即可。这种处理方式是大家比较容易想到的，但这样做会损失一定的效率。不同于上面的处理方式，HashMap的实现思路则是很独特。在上节中，在将普通链表转换为红黑树时，HashMap通过两个额外的引用next和prev保留了原链表的节点顺序。这样再对红黑树进行重新映射时，完全可以按照映射链表的方式进行。这样就避免了将红黑树转换成链表后再进行映射，无形中提高了效率。

来看一下红黑树拆分的具体实现：

```java
        final void split(HashMap<K,V> map, Node<K,V>[] tab, int index, int bit) {
            TreeNode<K,V> b = this;
            // Relink into lo and hi lists, preserving order
            TreeNode<K,V> loHead = null, loTail = null;
            TreeNode<K,V> hiHead = null, hiTail = null;
            int lc = 0, hc = 0;
            /* 
            * 红黑树节点仍然保留了 next 引用，故仍可以按链表方式遍历红黑树。
            * 下面的循环是对红黑树节点进行分组，与上面类似
            */
            for (TreeNode<K,V> e = b, next; e != null; e = next) {
                next = (TreeNode<K,V>)e.next;
                e.next = null;
                if ((e.hash & bit) == 0) {
                    if ((e.prev = loTail) == null)
                        loHead = e;
                    else
                        loTail.next = e;
                    loTail = e;
                    ++lc;
                }
                else {
                    if ((e.prev = hiTail) == null)
                        hiHead = e;
                    else
                        hiTail.next = e;
                    hiTail = e;
                    ++hc;
                }
            }

            if (loHead != null) {
                // 如果 loHead 不为空，且链表长度小于等于 6，则将红黑树转成链表
                if (lc <= UNTREEIFY_THRESHOLD)
                    tab[index] = loHead.untreeify(map);
                else {
                    tab[index] = loHead;
                    //hiHead == null时，所有节点仍然在原位置，树结构不变，无需重新树化
                    if (hiHead != null) // (else is already treeified)
                        loHead.treeify(tab);
                }
            }
            //与上面类似
            if (hiHead != null) {
                if (hc <= UNTREEIFY_THRESHOLD)
                    tab[index + bit] = hiHead.untreeify(map);
                else {
                    tab[index + bit] = hiHead;
                    if (loHead != null)
                        hiHead.treeify(tab);
                }
            }
        }
```
通过源码我们可以看出，重新映射红黑树的逻辑和重新映射链表的基本一致。不同的地方在于，重新映射后，会将红黑树拆分成两条由TreeNode组成的链表。如果链表长度小于UNTREEIFY_THRESHOLD，则将链表转换成普通链表。否则根据条件重新将TreeNode链表树化。举个例子说明一下，假设扩容后，重新映射上图的红黑树，映射结果如下：

![红黑树拆分](https://i.loli.net/2019/08/26/mDgpA75W89PdhCt.jpg)

**红黑树链化**

前面说过，红黑树中仍然保留了原链表节点顺序。有了这个前提，再将红黑树转成链表就简单多了，仅需将 TreeNode 链表转成 Node 类型的链表即可。相关代码如下：

```java
        final Node<K,V> untreeify(HashMap<K,V> map) {
            Node<K,V> hd = null, tl = null;
            for (Node<K,V> q = this; q != null; q = q.next) {
                Node<K,V> p = map.replacementNode(q, null);
                if (tl == null)
                    hd = p;
                else
                    tl.next = p;
                tl = p;
            }
            return hd;
        }

```

4. 总结

总结一下，添加数据的整体流程：

![添加数据整体流程](https://i.loli.net/2019/08/26/k5YKdmLyAFcEivM.png)

给出添加数据与JDK 1.7的区别内容如下图所示：

![插入数据的异同](https://i.loli.net/2019/08/26/P4Q5bwxr2Udh98C.png)

**3. get()方法的解析**

get()函数的流程如下所示：
- (1)计算需获取数据的hash值(计算过程同put()函数);
- (2)计算存放在数据table中的位置(计算过程同put()函数);
- (3)依次在数组、链表、红黑树中查找(通过equals()判断);
- (4)获取后，判断所获取的数据是否为空(若为空，则返回null).

```java
    public V get(Object key) {
        Node<K,V> e;
    // 1. 计算需获取数据的hash值
    // 2. 通过getNode（）获取所查询的数据 ->>分析1
    // 3. 获取后，判断数据是否为空
        return (e = getNode(hash(key), key)) == null ? null : e.value;
    }

    //分析1
    final Node<K,V> getNode(int hash, Object key) {
        Node<K,V>[] tab; Node<K,V> first, e; int n; K k;
        // 1. 计算存放在数组table中的位置
        if ((tab = table) != null && (n = tab.length) > 0 &&
            (first = tab[(n - 1) & hash]) != null) {
                // a. 先在数组中找，若存在，则直接返回
            if (first.hash == hash && // always check first node
                ((k = first.key) == key || (key != null && key.equals(k))))
                return first;
                // b. 若数组中没有，则到红黑树中寻找
            if ((e = first.next) != null) {
                if (first instanceof TreeNode)
                    return ((TreeNode<K,V>)first).getTreeNode(hash, key);
                    // c. 若红黑树中也没有，则通过遍历，到链表中寻找
                do {
                    if (e.hash == hash &&
                        ((k = e.key) == key || (key != null && key.equals(k))))
                        return e;
                } while ((e = e.next) != null);
            }
        }
        return null;
    }
```

**4.HashMap其他操作的解析**

```java

void clear(); // 清除哈希表中的所有键值对
int size();  // 返回哈希表中所有 键值对的数量 = 数组中的键值对 + 链表中的键值对
boolean isEmpty(); // 判断HashMap是否为空；size == 0时 表示为 空 

void putAll(Map<? extends K, ? extends V> m);  // 将指定Map中的键值对 复制到 此Map中
V remove(Object key);  // 删除该键值对

boolean containsKey(Object key); // 判断是否存在该键的键值对；是 则返回true
boolean containsValue(Object value);  // 判断是否存在该值的键值对；是 则返回true
 
```

##### 5.源码总结

最后，从三个方面来总结一下整个源码的内容：

1. 数据结构与主要参数

![数据结构与主要参数](https://i.loli.net/2019/08/26/ZHYNjRhCfeA4K6o.png)

2. 添加与查询数据流程

![添加与查询数据](https://i.loli.net/2019/08/26/fvMbR8KO5CFqWXU.png)

3. 扩容机制
   
![扩容机制](https://i.loli.net/2019/08/26/dyPDNMJ2awczulH.png)

**参考文章：**

[Java源码分析：关于 HashMap 1.8 的重大更新](https://blog.csdn.net/carson_ho/article/details/79373134)

[HashMap源码分析](https://www.cnblogs.com/winterfells/p/8876888.html)

[HashMap 源码详细分析(JDK1.8)](https://www.imooc.com/article/30668)

[HashMap JDK1.8实现原理](https://www.cnblogs.com/duodushuduokanbao/p/9492952.html)

[面试 | Java8 HashMap原理](https://cloud.tencent.com/developer/article/1376741)

[Java7/8中的HashMap和ConcurrentHashMap源码分析](http://www.360doc.com/content/18/1129/05/36367108_798028120.shtml)

[Java 8系列之重新认识HashMap](https://zhuanlan.zhihu.com/p/21673805)

#### 1.2.4 LinkedHashMap源码分析

> LinkedHashMap继承自HashMap，在HashMap的基础上，通过维护一条双向链表，解决了HashMap不能随时保持遍历顺序和插入顺序一致的问题。除此之外，LinkedHashMap也对访问顺序提供了相关的支持。在一些场景下，该特性很有用，例如缓存。在实现上，LinkedHashMap很多方法直接继承自HashMap，仅为维护双向链表覆写了部分方法。

